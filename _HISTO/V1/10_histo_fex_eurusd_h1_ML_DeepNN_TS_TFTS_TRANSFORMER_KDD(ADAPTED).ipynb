{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b2e147",
   "metadata": {},
   "source": [
    "# Applications d'algo Deep Learning (NN) adaptés aux Time Series\n",
    "\n",
    "Il existe plusieurs types de modèles adaptés aux Time Series. Leur particularité est de ne pas utiliser simplement les données comme des évenements indépendants mais de conserver une \"mémoire\" des évenements précédents pour mieux analyser un instant T.\n",
    "\n",
    "Recemment les modeles de type Transformer avec attention qui ont connus de gros succès en NLP, ont été adaptés pour des Timeseries avec des résultats qui dépassent ceux des autres types de modèles (GRU, LSTM, ...). L'avantage de ces modèles, avec le système d'attention est que contrairement aux RNN qui ont des fenêtrages de temps fixés sur une periode donnée, ceux-ci peuvent détecter des pattern sur du très long terme. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c74e9",
   "metadata": {},
   "source": [
    "#### First of all set randomeness in order to have comparable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174a0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31832bde",
   "metadata": {},
   "source": [
    "## Input parameters\n",
    "\n",
    "To be reviewed:adapt before 1st launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd01aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'NN_TS_TFTS_CUSTO_KDD_TRANSFORMER_02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32020c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathModelWeights = 'weights/' + modelName + '_WEIGHTS.h5'\n",
    "pathModel = 'model/' + modelName + '_MODEL.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592727c",
   "metadata": {},
   "source": [
    "## Reproduction du modèle utilisé lors du challenge KDD de 2022\n",
    "\n",
    "3e place du concours. \n",
    "\n",
    "Sur la base du code GIT : https://github.com/LongxingTan/KDDCup2022-WPF\n",
    "\n",
    "On va :\n",
    "1/ Reproduire le traitement réalisé ici danbs un premier temps avec le dataset original (Wind Power)\n",
    "2/ Adapter le traitement à notre timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bdb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f26a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os.path\n",
    "import joblib\n",
    "import itertools\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d15cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc65b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8890cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Convolution1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.layers import LSTM, GRU, TimeDistributed, Conv1D, ConvLSTM2D, BatchNormalization\n",
    "from tensorflow.keras.layers import LayerNormalization, SpatialDropout1D, BatchNormalization, AveragePooling1D\n",
    "\n",
    "\n",
    "\n",
    "from attention import Attention\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abbd347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tfts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "146d5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfts\n",
    "from tfts import AutoModel, AutoConfig, KerasTrainer\n",
    "from tfts.models.seq2seq import Seq2seq\n",
    "from tfts.models.wavenet import WaveNet\n",
    "from tfts.models.transformer import Transformer\n",
    "from tfts.models.bert import Bert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae8f7b",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbc8257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = 'postgresql://postgres:Juw51000@localhost/tradingIA'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660c556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>mopen</th>\n",
       "      <th>mclose</th>\n",
       "      <th>mhigh</th>\n",
       "      <th>mlow</th>\n",
       "      <th>mvolume</th>\n",
       "      <th>mspread</th>\n",
       "      <th>ima</th>\n",
       "      <th>ima2</th>\n",
       "      <th>ima4</th>\n",
       "      <th>...</th>\n",
       "      <th>istos4</th>\n",
       "      <th>imom</th>\n",
       "      <th>imom2</th>\n",
       "      <th>imom4</th>\n",
       "      <th>rProfitBuy</th>\n",
       "      <th>rSwapBuy</th>\n",
       "      <th>rProfitBTrigger</th>\n",
       "      <th>rProfitSell</th>\n",
       "      <th>rSwapSell</th>\n",
       "      <th>rProfitSTrigger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946861200</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>194</td>\n",
       "      <td>50</td>\n",
       "      <td>1.008242</td>\n",
       "      <td>1.007963</td>\n",
       "      <td>1.006779</td>\n",
       "      <td>...</td>\n",
       "      <td>70.129870</td>\n",
       "      <td>100.536033</td>\n",
       "      <td>100.615935</td>\n",
       "      <td>100.565982</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-3.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>946864800</td>\n",
       "      <td>1.0129</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>1.0141</td>\n",
       "      <td>1.0120</td>\n",
       "      <td>113</td>\n",
       "      <td>50</td>\n",
       "      <td>1.008733</td>\n",
       "      <td>1.008175</td>\n",
       "      <td>1.006973</td>\n",
       "      <td>...</td>\n",
       "      <td>72.331461</td>\n",
       "      <td>100.675340</td>\n",
       "      <td>100.815515</td>\n",
       "      <td>100.495688</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>946868400</td>\n",
       "      <td>1.0140</td>\n",
       "      <td>1.0171</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0134</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>1.009517</td>\n",
       "      <td>1.008588</td>\n",
       "      <td>1.007215</td>\n",
       "      <td>...</td>\n",
       "      <td>76.041667</td>\n",
       "      <td>101.073239</td>\n",
       "      <td>101.002979</td>\n",
       "      <td>100.902778</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>946872000</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>1.0175</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>1.010350</td>\n",
       "      <td>1.008958</td>\n",
       "      <td>1.007462</td>\n",
       "      <td>...</td>\n",
       "      <td>78.688525</td>\n",
       "      <td>100.872410</td>\n",
       "      <td>100.962493</td>\n",
       "      <td>100.882411</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>946875600</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>1.0164</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>1.010975</td>\n",
       "      <td>1.009296</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>...</td>\n",
       "      <td>78.511530</td>\n",
       "      <td>100.703249</td>\n",
       "      <td>100.893123</td>\n",
       "      <td>100.813089</td>\n",
       "      <td>-2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       epoch   mopen  mclose   mhigh    mlow  mvolume  mspread       ima  \\\n",
       "0  946861200  1.0073  1.0128  1.0132  1.0073      194       50  1.008242   \n",
       "1  946864800  1.0129  1.0137  1.0141  1.0120      113       50  1.008733   \n",
       "2  946868400  1.0140  1.0171  1.0173  1.0134      149       50  1.009517   \n",
       "3  946872000  1.0170  1.0175  1.0190  1.0170      214       50  1.010350   \n",
       "4  946875600  1.0173  1.0167  1.0177  1.0164      162       50  1.010975   \n",
       "\n",
       "       ima2      ima4  ...     istos4        imom       imom2       imom4  \\\n",
       "0  1.007963  1.006779  ...  70.129870  100.536033  100.615935  100.565982   \n",
       "1  1.008175  1.006973  ...  72.331461  100.675340  100.815515  100.495688   \n",
       "2  1.008588  1.007215  ...  76.041667  101.073239  101.002979  100.902778   \n",
       "3  1.008958  1.007462  ...  78.688525  100.872410  100.962493  100.882411   \n",
       "4  1.009296  1.007677  ...  78.511530  100.703249  100.893123  100.813089   \n",
       "\n",
       "   rProfitBuy  rSwapBuy  rProfitBTrigger  rProfitSell  rSwapSell  \\\n",
       "0        3.64       0.0               TO        -3.07        0.0   \n",
       "1        2.56       0.0               TO        -3.15        0.0   \n",
       "2       -0.10       0.0               TO        -0.88        0.0   \n",
       "3       -2.36       0.0               TO         1.38        0.0   \n",
       "4       -2.95       0.0               SL         5.74        0.0   \n",
       "\n",
       "   rProfitSTrigger  \n",
       "0               SL  \n",
       "1               SL  \n",
       "2               TO  \n",
       "3               TO  \n",
       "4               TP  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"select * from fex_eurusd_h1\", conn);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0bf777",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f8ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['targetBuy'] = df['rProfitBuy'] + df['rSwapBuy']\n",
    "df['targetSell'] = df['rProfitSell'] + df['rSwapSell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab1a223f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145559, 27)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNotNa = df[df['rProfitBTrigger'].notna()]\n",
    "dfCleanRow = dfNotNa[dfNotNa['epoch'] < 1690484400]\n",
    "dfClean = dfCleanRow.drop(['rProfitBuy', 'rSwapBuy', 'rProfitSell', 'rSwapSell', 'rProfitSTrigger', 'rProfitBTrigger'], axis=1)\n",
    "dfClean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648cdcf",
   "metadata": {},
   "source": [
    "### Transposition en problème de classification binaire\n",
    "\n",
    "On peut simplifier la question de base qui est de savoir quel est le moment du profit (Buy/Sell) en question binaire, à savoir est-ce que le trade à un instant T (Buy et Sell) entrainera une perte (0) ou un gain (1) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "057ca2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin = dfClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f56b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145559, 29)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanBin['targetProfitBuy'] = dfCleanBin['targetBuy'].apply(lambda x: 1 if x > 0 else 0)\n",
    "dfCleanBin['targetProfitSell'] = dfCleanBin['targetSell'].apply(lambda x: 1 if x > 0 else 0)\n",
    "dfCleanBin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4000208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37148510226093884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetProfitBuy']) / dfCleanBin.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9cf55",
   "metadata": {},
   "source": [
    "Qu'il s'agisse des Profits Buy ou Sell on est à environ 37% de target Profit pour 63% de perte. Les classes sont donc plutôt équilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed19d79",
   "metadata": {},
   "source": [
    "### Glissement des valeurs Target (prévision)\n",
    "\n",
    "Pour la prévision les valeurs à prédire (profit du trade) sont les valeurs qui concernent la periode à venir du trade (T+1) en fonction des features observées sur la periode actuelle (T). On doit donc glisser les valeurs de Target de T+1 vers T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca6ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin['targetProfitBuy'] = dfCleanBin['targetProfitBuy'].shift(-1)\n",
    "dfCleanBin['targetProfitSell'] = dfCleanBin['targetProfitSell'].shift(-1)\n",
    "dfCleanBin['targetSell'] = dfCleanBin['targetSell'].shift(-1)\n",
    "dfCleanBin['targetBuy'] = dfCleanBin['targetBuy'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43268e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin = dfCleanBin[dfCleanBin['targetProfitSell'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02fee826",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin.set_index('epoch', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc14753",
   "metadata": {},
   "source": [
    "### Dataset de bases pour le model (Close price Only)\n",
    "\n",
    "- **dfBasisB** : Close Price Only -> Only use Price from previous periods to predict Next Trade Profit or Not\n",
    "- **dfRawB**   : Close, High, Low -> Use Price CLose and Low & High "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "271946e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBasisB = dfCleanBin[['mclose', 'targetProfitBuy']]\n",
    "dfRawB = dfCleanBin[['mclose', 'mhigh', 'mlow', 'targetProfitBuy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b10d9e",
   "metadata": {},
   "source": [
    "### dfRawB [Close]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b21a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfBasisB.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff923c18",
   "metadata": {},
   "source": [
    "#### Split DataFrame in train / valid /test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c7ac766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTestDatasets(dfData, part1=.8):\n",
    "    idxSep = round(len(dfData) * part1) - 1\n",
    "    dfPart1, dfPart2 = dfData[0:idxSep], dfData[idxSep:len(dfData)-1]\n",
    "    return dfPart1, dfPart2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1522c13c",
   "metadata": {},
   "source": [
    "Split into (Train + Valid) / Test datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a524596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dTrainVal, dTest = getTrainTestDatasets(df, .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156872c",
   "metadata": {},
   "source": [
    "Split into Train / Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f03043bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dTrain, dVal = getTrainTestDatasets(dTrainVal, .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eeef901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train shape :  (104799, 2)\n",
      " Valid shape :  (11645, 2)\n",
      " Test shape :  (29112, 2)\n"
     ]
    }
   ],
   "source": [
    "print(' Train shape : ', dTrain.shape)\n",
    "print(' Valid shape : ', dVal.shape)\n",
    "print(' Test shape : ', dTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51427c",
   "metadata": {},
   "source": [
    "#### Normalize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7bde907",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetColumn = 'targetProfitBuy'\n",
    "featureColumns = df.drop(columns=[targetColumn]).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fba1cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66209bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dTrain[featureColumns] = scaler.fit_transform(dTrain[featureColumns])\n",
    "dVal[featureColumns] = scaler.fit_transform(dVal[featureColumns])\n",
    "dTest[featureColumns] = scaler.fit_transform(dTest[featureColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95583dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "lookback = 1 * 7 * 24    # Nb Weeks\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780b2c5",
   "metadata": {},
   "source": [
    "#### Reader object used to store and give access to Training data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38086d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data, \n",
    "        target_column_idx,           # target index  columns\n",
    "        feature_column_idx,          # feature index columns\n",
    "        lookback,                    # Windowed Timestep Frame size\n",
    "        idxStart,                    # start idx for \n",
    "        idxEnd\n",
    "        ): \n",
    "        \"\"\" \n",
    "        data: 2D array, for each idx, choose its history and target\n",
    "        \"\"\"    \n",
    "        self.data = data.values        \n",
    "        self.target_column_idx = target_column_idx\n",
    "        self.feature_column_idx = feature_column_idx\n",
    "        self.lookback = lookback\n",
    "        self.idxStart = idxStart\n",
    "        self.idxEnd = idxEnd\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.idxEnd\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Create timestep Window indexes based on lookback setting\n",
    "        idx_start = idx - self.lookback\n",
    "        idx_end = idx\n",
    "        feature = self.data[idx_start:idx_end, self.feature_column_idx]  \n",
    "        target = self.data[idx, self.target_column_idx]\n",
    "        #targetResh = target.reshape(1,1)\n",
    "        #print(self.data.shape)\n",
    "        #print(feature.shape, targetResh.shape)\n",
    "        return feature, target  #feature, target\n",
    "\n",
    "    def iter(self):\n",
    "        # Need to have as many previous values as set in lookckack in order to produce Windowed Tserie\n",
    "        for i in range(self.idxStart + self.lookback, self.idxEnd):   \n",
    "            yield self[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1078250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, data_reader, feature_size, target_size):\n",
    "        self.data_reader = data_reader\n",
    "        self.lookback = data_reader.lookback\n",
    "        self.feature_size = feature_size\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __call__(self, batch_size, shuffle=False, drop_remainder=False): \n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            self.data_reader.iter,\n",
    "            # output_types=(tf.float32, tf.float32),\n",
    "            output_signature=( \n",
    "                tf.TensorSpec(shape=(self.lookback, self.feature_size), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(self.target_size), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1000)\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=drop_remainder).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bedd0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mclose</th>\n",
       "      <th>targetProfitBuy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946861200</th>\n",
       "      <td>0.243479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946864800</th>\n",
       "      <td>0.244636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946868400</th>\n",
       "      <td>0.249004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946872000</th>\n",
       "      <td>0.249518</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946875600</th>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mclose  targetProfitBuy\n",
       "epoch                               \n",
       "946861200  0.243479              1.0\n",
       "946864800  0.244636              0.0\n",
       "946868400  0.249004              0.0\n",
       "946872000  0.249518              0.0\n",
       "946875600  0.248490              0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f0b2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMinIdx, trainMaxIdx = 0, len(dTrain) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a5f644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 104798)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMinIdx, trainMaxIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd0d1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_idx = [df.columns.get_loc(targetColumn)]\n",
    "feature_column_idx = [df.columns.get_loc(c) for c in featureColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1526376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_reader = DataReader(\n",
    "        data = dTrain, \n",
    "        target_column_idx = target_column_idx,\n",
    "        feature_column_idx = feature_column_idx,\n",
    "        lookback = lookback,\n",
    "        idxStart = trainMinIdx,\n",
    "        idxEnd = trainMaxIdx\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b7550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "        train_data_reader, \n",
    "        len(featureColumns), \n",
    "        1)(batch_size=BATCH_SIZE, shuffle=False, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021b092",
   "metadata": {},
   "source": [
    "#### Validation reader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b6397d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valMinIdx, valMaxIdx = 0, len(dVal) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37a0fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_reader = DataReader(\n",
    "        data = dVal, \n",
    "        target_column_idx = target_column_idx,\n",
    "        feature_column_idx = feature_column_idx,\n",
    "        lookback = lookback,\n",
    "        idxStart = valMinIdx,\n",
    "        idxEnd = valMaxIdx\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1532f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_loader = DataLoader(\n",
    "    valid_data_reader, \n",
    "    len(featureColumns), \n",
    "    1)(batch_size=BATCH_SIZE, shuffle=False, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62f200d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104798 11644\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_reader), len(valid_data_reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a70c5",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a93dee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_model = 'bert' # Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fb7ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureNum = len(featureColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee646c",
   "metadata": {},
   "source": [
    "#### Define Model Format Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ce2c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputM = (Input([lookback, featureNum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9c518d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25575c",
   "metadata": {},
   "source": [
    "#### Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcace87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAttention(tf.keras.layers.Layer):  \n",
    "    \"\"\" Multi-head attention layer\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, num_heads, attention_dropout=0.):\n",
    "        if hidden_size % num_heads:\n",
    "            raise ValueError(\"Hidden size ({}) must be divisible by the number of heads ({}).\"\n",
    "                             .format(hidden_size, num_heads))\n",
    "        super(CustomAttention, self).__init__()\n",
    "        self.units = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dropout = attention_dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_q = Dense(self.units, use_bias=False)\n",
    "        self.dense_k = Dense(self.units, use_bias=False)\n",
    "        self.dense_v = Dense(self.units, use_bias=False)\n",
    "        self.dropout = Dropout(rate=self.attention_dropout)\n",
    "        super(CustomAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, q, k, v, mask=None):\n",
    "        \"\"\"use query and key generating an attention multiplier for value, multi_heads to repeat it\n",
    "\n",
    "        :param q: Query with shape batch * seq_q * fea\n",
    "        :type q: _type_\n",
    "        :param k: Key with shape batch * seq_k * fea\n",
    "        :type k: _type_\n",
    "        :param v: value with shape batch * seq_v * fea\n",
    "        :type v: _type_\n",
    "        :param mask: important to avoid the leaks, defaults to None\n",
    "        :type mask: _type_, optional\n",
    "        :return: tensor with shape batch * key_sequence * (units * num_heads)\n",
    "        :rtype: _type_\n",
    "        \"\"\"\n",
    "        \n",
    "        q = self.dense_q(q)  # project the query/key/value to num_heads * units\n",
    "        k = self.dense_k(k)\n",
    "        v = self.dense_v(v)\n",
    "\n",
    "        q_ = tf.concat(tf.split(q, self.num_heads, axis=2), axis=0)  # multi-heads transfer to\n",
    "        k_ = tf.concat(tf.split(k, self.num_heads, axis=2), axis=0)\n",
    "        v_ = tf.concat(tf.split(v, self.num_heads, axis=2), axis=0)\n",
    "\n",
    "        score = tf.linalg.matmul(q_, k_, transpose_b=True)  # => (batch*heads) * seq_q * seq_k\n",
    "        score /= tf.cast(tf.shape(q_)[-1], tf.float32) ** 0.5\n",
    "\n",
    "        if mask is not None:\n",
    "            score = score * tf.cast(mask, tf.float32)\n",
    "\n",
    "        score = tf.nn.softmax(score)\n",
    "        score = self.dropout(score)\n",
    "\n",
    "        outputs = tf.linalg.matmul(score, v_)  # (batch*heads) * seq_q * units\n",
    "        outputs = tf.concat(tf.split(outputs, self.num_heads, axis=0), axis=2)\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'num_heads': self.num_heads,\n",
    "            'attention_dropout': self.attention_dropout\n",
    "        }\n",
    "        base_config = super(CustomAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "953e2020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size, num_heads, attention_dropout=0.):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.attention = CustomAttention(hidden_size, num_heads, attention_dropout=attention_dropout)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return self.attention(x, x, x, mask)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(SelfAttention, self).get_config()\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0567a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size, filter_size, relu_dropout):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.filter_size = filter_size\n",
    "        self.relu_dropout = relu_dropout      \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.filter_dense_layer = Dense(self.filter_size, use_bias=True, activation='relu')\n",
    "        self.output_dense_layer = Dense(self.hidden_size, use_bias=True)\n",
    "        self.drop = Dropout(self.relu_dropout)\n",
    "        super(FeedForwardNetwork, self).build(input_shape)  \n",
    "\n",
    "    def call(self, x):\n",
    "        output = self.filter_dense_layer(x)\n",
    "        output = self.drop(output)\n",
    "        output = self.output_dense_layer(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"hidden_size\": self.hidden_size,\n",
    "            \"filter_size\": self.filter_size,\n",
    "            \"relu_dropout\": self.relu_dropout,\n",
    "        }\n",
    "        base_config = super(FeedForwardNetwork, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57057fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_encoder_layers, attention_hidden_sizes, num_heads, attention_dropout, ffn_hidden_sizes, ffn_filter_sizes, ffn_dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_encoder_layers = n_encoder_layers\n",
    "        self.attention_hidden_sizes = attention_hidden_sizes\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.ffn_hidden_sizes = ffn_hidden_sizes\n",
    "        self.ffn_filter_sizes = ffn_filter_sizes\n",
    "        self.ffn_dropout = ffn_dropout\n",
    "        self.layers = []\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        for _ in range(self.n_encoder_layers):\n",
    "            attention_layer = SelfAttention(self.attention_hidden_sizes,  self.num_heads,  self.attention_dropout)\n",
    "            feed_forward_layer = FeedForwardNetwork(self.ffn_hidden_sizes, self.ffn_filter_sizes, self.ffn_dropout)\n",
    "            ln_layer1 = LayerNormalization(epsilon=1e-6, dtype=\"float32\")\n",
    "            ln_layer2 = LayerNormalization(epsilon=1e-6, dtype=\"float32\")\n",
    "            self.layers.append([attention_layer, ln_layer1, feed_forward_layer, ln_layer2])\n",
    "        super(Encoder, self).build(input_shape)    \n",
    "\n",
    "    def call(self, encoder_inputs, src_mask=None):\n",
    "        x = encoder_inputs\n",
    "        for _, layer in enumerate(self.layers):\n",
    "            attention_layer, ln_layer1, ffn_layer, ln_layer2 = layer\n",
    "            enc = x\n",
    "            enc = attention_layer(enc, src_mask)          \n",
    "            enc1 = ln_layer1(x + enc)  # residual connect\n",
    "            enc1 = ffn_layer(enc1)\n",
    "            x = ln_layer2(enc + enc1)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'n_encoder_layers': self.n_encoder_layers,\n",
    "            'attention_hidden_sizes': self.attention_hidden_sizes,\n",
    "            'num_heads': self.num_heads,\n",
    "            'attention_dropout': self.attention_dropout,\n",
    "            'ffn_hidden_sizes': self.ffn_hidden_sizes,\n",
    "            'ffn_filter_sizes': self.ffn_filter_sizes,\n",
    "            'ffn_dropout': self.ffn_dropout\n",
    "        }\n",
    "        base_config = super(Encoder, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac0d9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\" \n",
    "    x: batch * time * feature\n",
    "    outout: batch * time * new_attention_size）\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.token_weights = self.add_weight(\n",
    "            name='token_weights',\n",
    "            shape=[input_shape[-1], self.embed_size],\n",
    "            initializer=tf.random_normal_initializer(mean=0., stddev=self.embed_size ** -0.5))\n",
    "        super(TokenEmbedding, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = tf.einsum('bsf,fk->bsk', x, self.token_weights)\n",
    "        return y\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'embed_size': self.embed_size\n",
    "        }\n",
    "        base_config = super(TokenEmbedding, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b680cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert(object):\n",
    "    def __init__(self, predict_sequence_length, custom_model_params) -> None:\n",
    "\n",
    "        self.params = custom_model_params        \n",
    "        self.predict_sequence_length = predict_sequence_length\n",
    "\n",
    "        self.encoder_embedding = TokenEmbedding(custom_model_params['attention_hidden_sizes'])\n",
    "        self.spatial_drop = SpatialDropout1D(0.1)\n",
    "        self.encoder = Encoder(\n",
    "            custom_model_params['n_encoder_layers'], \n",
    "            custom_model_params['attention_hidden_sizes'], \n",
    "            custom_model_params['num_heads'], \n",
    "            custom_model_params['attention_dropout'], \n",
    "            custom_model_params['ffn_hidden_sizes'], \n",
    "            custom_model_params['ffn_filter_sizes'], \n",
    "            custom_model_params['ffn_dropout'])\n",
    "        \n",
    "        self.drop1 = Dropout(0.1)\n",
    "        self.dense1 = Dense(32, activation='relu')\n",
    "\n",
    "        self.drop2 = Dropout(0.1)\n",
    "        self.dense2 = Dense(16, activation='relu')  \n",
    "        \n",
    "        self.project1 = Dense(predict_sequence_length, activation='sigmoid') \n",
    "    \n",
    "    def __call__(self, inputs, teacher=None):\n",
    "        # inputs: \n",
    "        encoder_features = inputs\n",
    "\n",
    "        encoder_features = self.encoder_embedding(encoder_features)\n",
    "        memory = self.encoder(encoder_features, src_mask=None)  # batch * train_sequence * (hidden * heads)\n",
    "        encoder_output = memory[:, -1]\n",
    " \n",
    "        #encoder_output = self.drop1(encoder_output)\n",
    "        encoder_output = self.dense1(encoder_output)\n",
    "        #encoder_output = self.drop2(encoder_output)\n",
    "        encoder_output = self.dense2(encoder_output)\n",
    "        #encoder_output = self.drop2(encoder_output)\n",
    "\n",
    "        outputs = self.project1(encoder_output)       \n",
    "        #outputs = tf.expand_dims(outputs, -1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ad6e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_params = {\n",
    "    'n_encoder_layers': 1,\n",
    "    'use_token_embedding': False,\n",
    "    'attention_hidden_sizes': 32*1,\n",
    "    'num_heads': 1,\n",
    "    'attention_dropout': 0.,\n",
    "    'ffn_hidden_sizes': 32,\n",
    "    'ffn_filter_sizes': 32,  # should be same with attention_hidden_sizes\n",
    "    'ffn_dropout': 0.,\n",
    "    'layer_postprocess_dropout': 0.,\n",
    "    'skip_connect': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4d7b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfts_model(use_model, predict_sequence_length, custom_model_params=None):\n",
    "    if use_model.lower() == \"seq2seq\":\n",
    "        Model = Seq2seq(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    elif use_model.lower() == \"wavenet\":\n",
    "        Model = WaveNet(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    elif use_model.lower() == \"transformer\":\n",
    "        Model = Transformer(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    elif use_model.lower() == \"bert\":\n",
    "        Model = Bert(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    else:\n",
    "        raise ValueError(\"unsupported use_model of {} yet\".format(use_model))\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de621f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sequence_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "671c33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = build_tfts_model(\n",
    "        use_model=use_model, \n",
    "        predict_sequence_length=predict_sequence_length, \n",
    "        custom_model_params=custom_model_params\n",
    "    )(inputM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10ef8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputM, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "999a11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception('coucou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e2afee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 168, 1)]          0         \n",
      "                                                                 \n",
      " token_embedding (TokenEmbed  (None, 168, 32)          32        \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " encoder (Encoder)           (None, 168, 32)           5312      \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 32)               0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,945\n",
      "Trainable params: 6,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be13d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153f765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9dc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "395c40b7",
   "metadata": {},
   "source": [
    "#### Custom Loss fonction (based on Mean Square Error) used for the Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cab1db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):  \n",
    "    print(y_true.shape, y_pred.shape)\n",
    "    true, mask = tf.split(y_true, 2, axis=-1)   \n",
    "    mask = tf.cast(mask, dtype=tf.float32)  \n",
    "    true *= mask\n",
    "    y_pred *= mask\n",
    "    rmse_score = tf.math.sqrt(tf.reduce_mean(tf.square(true - y_pred)) + 1e-9)\n",
    "    return rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffe0430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-3)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b08099bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac4081ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = KerasTrainer(model, loss_fn='mse', optimizer=optimizer, strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6431435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "        'n_epochs': 1,\n",
    "        'batch_size': 1,\n",
    "        'learning_rate': 5e-3,\n",
    "        'verbose': 1,\n",
    "        'checkpoint': ModelCheckpoint(\n",
    "            'checkpoint/nn_FEX_EURUSD_H1{}.h5'.format(use_model), \n",
    "            monitor='val_loss', \n",
    "            save_weights_only=True, \n",
    "            save_best_only=False, \n",
    "            verbose=1),      \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88c0a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x00000235717D6C50>\n",
      "   3269/Unknown - 121s 37ms/step - loss: 0.2310\n",
      "Epoch 1: saving model to checkpoint\\nn_FEX_EURUSD_H1bert.h5\n",
      "3269/3269 [==============================] - 128s 39ms/step - loss: 0.2310 - val_loss: 0.2340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23571aa6830>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(train_data_loader, valid_dataset=valid_data_loader, **fit_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3169be4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4076e9a",
   "metadata": {},
   "source": [
    "## Calcul potential Profit\n",
    "\n",
    "=> Test dataset, as unused data by model, can be used to estimate benefits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3708e57",
   "metadata": {},
   "source": [
    "### Predict test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57299d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "testMinIdx, testMaxIdx = 0, len(dTest) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "891ea9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_reader = DataReader(\n",
    "        data = dTest, \n",
    "        target_column_idx = target_column_idx,\n",
    "        feature_column_idx = feature_column_idx,\n",
    "        lookback = lookback,\n",
    "        idxStart = testMinIdx,\n",
    "        idxEnd = testMaxIdx\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1eb4652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(\n",
    "    test_data_reader, \n",
    "    len(featureColumns), \n",
    "    1)(batch_size=BATCH_SIZE, shuffle=False, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b7fb1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 14s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(test_data_loader, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f64cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = dTest.iloc[-pred.shape[0]:]['targetProfitBuy'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "412e26d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.399116  ],\n",
       "       [0.39911595],\n",
       "       [0.39911595],\n",
       "       ...,\n",
       "       [0.3991112 ],\n",
       "       [0.39911127],\n",
       "       [0.39911136]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c91a5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "[fpr, tpr, thr] = roc_curve(true, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "520725fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3991337 , 0.39913374, 0.39913365, ..., 0.39907628, 0.39907622,\n",
       "       0.39907235], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6286c1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3847829092920354"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(true)/len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "014e4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProfit(dfCleanRow, dX_test, true, pred, lookback=100, specificity=.8, target='targetBuy'):\n",
    "    [fpr, tpr, thr] = roc_curve(true, pred, pos_label=1)\n",
    "    idx = np.max(np.where((1-fpr) > specificity)) \n",
    "    seuil = thr[idx]  \n",
    "    dfPred = pd.DataFrame(pred, columns = ['proba'])\n",
    "    #Get rows index with positive proba (proba > seuil)\n",
    "    xRows = dfPred[dfPred['proba']>seuil].index.to_numpy()\n",
    "    #Get matching index (epoch timestamp) from dX_test => Periods with proba > seuil\n",
    "    xEpochs = dX_test.iloc[lookback-1:,:].iloc[xRows].index.to_numpy()\n",
    "    dfCleanEpochIdx = dfCleanRow.set_index('epoch')\n",
    "    profit = dfCleanEpochIdx.loc[xEpochs][target].sum()\n",
    "    profitPerTrade = profit / len(xRows)\n",
    "    return profit, profitPerTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b61b368c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-174.99, -0.1307847533632287)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateProfit(dfCleanRow, dTest, true, pred, lookback=lookback, specificity=.95, target='targetBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a5f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730eab99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
