{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b2e147",
   "metadata": {},
   "source": [
    "# Applications d'algo Deep Learning (NN) adaptés aux Time Series\n",
    "\n",
    "Il existe plusieurs types de modèles adaptés aux Time Series. Leur particularité est de ne pas utiliser simplement les données comme des évenements indépendants mais de conserver une \"mémoire\" des évenements précédents pour mieux analyser un instant T.\n",
    "\n",
    "Recemment les modeles de type Transformer avec attention qui ont connus de gros succès en NLP, ont été adaptés pour des Timeseries avec des résultats qui dépassent ceux des autres types de modèles (GRU, LSTM, ...). L'avantage de ces modèles, avec le système d'attention est que contrairement aux RNN qui ont des fenêtrages de temps fixés sur une periode donnée, ceux-ci peuvent détecter des pattern sur du très long terme. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c74e9",
   "metadata": {},
   "source": [
    "#### First of all set randomeness in order to have comparable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174a0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31832bde",
   "metadata": {},
   "source": [
    "## Input parameters\n",
    "\n",
    "To be reviewed:adapt before 1st launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd01aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'NN_TS_TFTS_CUSTO_KDD_TRANSFORMER_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32020c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathModelWeights = 'weights/' + modelName + '_WEIGHTS.h5'\n",
    "pathModel = 'model/' + modelName + '_MODEL.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592727c",
   "metadata": {},
   "source": [
    "## Reproduction du modèle utilisé lors du challenge KDD de 2022\n",
    "\n",
    "3e place du concours. \n",
    "\n",
    "Sur la base du code GIT : https://github.com/LongxingTan/KDDCup2022-WPF\n",
    "\n",
    "On va :\n",
    "1/ Reproduire le traitement réalisé ici danbs un premier temps avec le dataset original (Wind Power)\n",
    "2/ Adapter le traitement à notre timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bdb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f26a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os.path\n",
    "import joblib\n",
    "import itertools\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d15cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc65b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8890cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Convolution1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.layers import LSTM, GRU, TimeDistributed, Conv1D, ConvLSTM2D, BatchNormalization\n",
    "from attention import Attention\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abbd347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tfts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "146d5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfts\n",
    "from tfts import AutoModel, AutoConfig, KerasTrainer\n",
    "from tfts.models.seq2seq import Seq2seq\n",
    "from tfts.models.wavenet import WaveNet\n",
    "from tfts.models.transformer import Transformer\n",
    "from tfts.models.bert import Bert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4436575",
   "metadata": {},
   "source": [
    "## Classes KDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdaf1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data, \n",
    "        train_sequence_length=10*24*6, \n",
    "        predict_sequence_length=48 * 6, \n",
    "        idx=None,  # start idx for \n",
    "        target_aggs=1,\n",
    "        target_column_idx=[-2, -1],  # target and target\n",
    "        feature_column_idx_short=[0],\n",
    "        feature_column_idx_long=[-2, -1],\n",
    "        ): \n",
    "        \"\"\" \n",
    "        data: 2D array, for each idx, choose its history and target\n",
    "        \"\"\"    \n",
    "        self.train_sequence_length = train_sequence_length\n",
    "        self.predict_sequence_length = predict_sequence_length\n",
    "        self.target_aggs = target_aggs\n",
    "        self.target_column_idx = target_column_idx\n",
    "        self.feature_column_idx_short = feature_column_idx_short\n",
    "        self.feature_column_idx_long = feature_column_idx_long\n",
    "\n",
    "        if idx is None:\n",
    "            drop_idx = data.groupby(['TurbID']).tail(predict_sequence_length - 1).index.tolist()\n",
    "            drop_idx += data.groupby(['TurbID']).head(train_sequence_length).index.tolist()\n",
    "            all_idx = data.index.to_list()\n",
    "            self.idx = [i for i in all_idx if i not in drop_idx]\n",
    "        else:\n",
    "            self.idx = idx\n",
    "        self.data = data.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        train_begin_idx = idx - self.train_sequence_length\n",
    "        test_end_idx = idx + self.predict_sequence_length\n",
    "        turbine_id = self.data[idx, 0]\n",
    "        raw= self.data[train_begin_idx:idx, self.feature_column_idx_short]  # train_seq * 10\n",
    "        raw_long = self.data[train_begin_idx: test_end_idx, self.feature_column_idx_long]\n",
    "        \n",
    "        teacher = self.data[idx: test_end_idx, self.target_column_idx[0]: self.target_column_idx[0]+1]\n",
    "        target = self.data[idx: test_end_idx, self.target_column_idx]\n",
    "        \n",
    "        return {'inputs': (turbine_id, raw, raw_long), 'teacher': teacher}, target\n",
    "\n",
    "    def iter(self):\n",
    "        for i in self.idx:\n",
    "            yield self[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e95376ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, data_reader, short_feature_size=10, long_feature_size=2, target_column_size=2):\n",
    "        self.data_reader = data_reader\n",
    "        self.train_sequence_length = data_reader.train_sequence_length\n",
    "        self.predict_sequence_length = data_reader.predict_sequence_length\n",
    "        self.target_aggs = data_reader.target_aggs\n",
    "        self.short_feature_size = short_feature_size\n",
    "        self.long_feature_size = long_feature_size\n",
    "        self.target_column_size = target_column_size\n",
    "\n",
    "    def __call__(self, batch_size, shuffle=False, drop_remainder=False): \n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            self.data_reader.iter,\n",
    "            # output_types=({'inputs':(tf.int32, tf.float32, tf.float32), 'teacher': tf.float32}, tf.float32),\n",
    "            output_signature=({'inputs': \n",
    "            (tf.TensorSpec(shape=(), dtype=tf.int32), \n",
    "            tf.TensorSpec(shape=(self.train_sequence_length, self.short_feature_size), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(self.train_sequence_length+self.predict_sequence_length, self.long_feature_size), dtype=tf.float32)), \n",
    "            'teacher': tf.TensorSpec(shape=(self.predict_sequence_length//self.target_aggs, 1), dtype=tf.float32)}, \n",
    "            tf.TensorSpec(shape=(self.predict_sequence_length//self.target_aggs, self.target_column_size ), dtype=tf.float32)\n",
    "        ))\n",
    "\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1000)\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=drop_remainder).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae8f7b",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66233298",
   "metadata": {},
   "source": [
    "#### nn_train.build_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b04582",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('KDD/raw/wtbdata_245days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "064e785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>509.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>542.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>509.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  \\\n",
       "0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   \n",
       "1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0   \n",
       "3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0   \n",
       "4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0   \n",
       "\n",
       "   Prtv    Patv  \n",
       "0   NaN     NaN  \n",
       "1 -0.25  494.66  \n",
       "2 -0.24  509.76  \n",
       "3 -0.26  542.53  \n",
       "4 -0.23  509.36  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94cdb733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4727520, 13) 245\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, np.max(data['Day']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a375ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['start_time'] = data['Day'].astype(str) + ' ' + data['Tmstamp'].astype(str) # Flag of the first of 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd9a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between \n",
    "train_days = range(1, 181)  # range(1, 231)\n",
    "valid_days = range(231, 246)  # range(231, 246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d86a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df_raw = data.loc[data['Day'].isin(valid_days)]  #  dataset part reserved after training for validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f970993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289440, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03706648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with next non missing value or prev for the same Turbine ID\n",
    "data[['Wspd', 'Wdir', 'Patv']] = data.groupby(['TurbID'])[['Wspd', 'Wdir', 'Patv']].apply(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c61f9345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494.66</td>\n",
       "      <td>1 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "      <td>1 00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>509.76</td>\n",
       "      <td>1 00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>542.53</td>\n",
       "      <td>1 00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>509.36</td>\n",
       "      <td>1 00:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  \\\n",
       "0       1    1   00:00  6.17 -3.99    NaN    NaN    NaN   NaN   NaN   NaN   \n",
       "1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0   \n",
       "3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0   \n",
       "4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0   \n",
       "\n",
       "   Prtv    Patv start_time  \n",
       "0   NaN  494.66    1 00:00  \n",
       "1 -0.25  494.66    1 00:10  \n",
       "2 -0.24  509.76    1 00:20  \n",
       "3 -0.26  542.53    1 00:30  \n",
       "4 -0.23  509.36    1 00:40  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1de03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate extrat time Features informations\n",
    "data['Hour'] = pd.to_datetime(data['Tmstamp'], format='%H:%M').dt.hour\n",
    "data['Minute'] = pd.to_datetime(data['Tmstamp'], format='%H:%M').dt.minute  \n",
    "data['MinuteofDay'] = data['Hour'] * 6 + data['Minute'] / 10   \n",
    "data['DayofWeek'] = data['Day'] // 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa783a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_valid'] = 1  # 1 means valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb4e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling to normalize data and optimize \n",
    "scaler = MinMaxScaler()\n",
    "data[['Wspd', 'Wdir', 'Prtv']] = scaler.fit_transform(data[['Wspd', 'Wdir', 'Prtv']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5764a635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "      <th>start_time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>MinuteofDay</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.23469</td>\n",
       "      <td>0.571311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494.66</td>\n",
       "      <td>1 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>0.23469</td>\n",
       "      <td>0.571311</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.8</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562729</td>\n",
       "      <td>494.66</td>\n",
       "      <td>1 00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TurbID  Day Tmstamp     Wspd      Wdir   Etmp  Itmp   Ndir  Pab1  Pab2  \\\n",
       "0       1    1   00:00  0.23469  0.571311    NaN   NaN    NaN   NaN   NaN   \n",
       "1       1    1   00:10  0.23469  0.571311  30.73  41.8  25.92   1.0   1.0   \n",
       "\n",
       "   Pab3      Prtv    Patv start_time  Hour  Minute  MinuteofDay  DayofWeek  \\\n",
       "0   NaN       NaN  494.66    1 00:00     0       0          0.0          0   \n",
       "1   1.0  0.562729  494.66    1 00:10     0      10          1.0          0   \n",
       "\n",
       "   is_valid  \n",
       "0         1  \n",
       "1         1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0e404",
   "metadata": {},
   "source": [
    "#### Create rolling indicators, with different lags and different aggreagate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b7d748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_column='Wspd'\n",
    "period=6\n",
    "lags=[6, 144]\n",
    "id_col='TurbID'\n",
    "agg_funs=['mean', 'max']\n",
    "feature_cols=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02f14dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in lags:\n",
    "    for agg_fun in agg_funs:\n",
    "        feature_col = roll_column + '_lag{}_roll{}_{}'.format(lag, period, agg_fun)\n",
    "        feature_cols.append(feature_col)\n",
    "        if id_col is not None:\n",
    "            data[feature_col] = data.groupby(id_col)[roll_column].transform(lambda x: x.shift(lag+1).rolling(period).agg(agg_fun))\n",
    "        else:\n",
    "            data[feature_col] = data[roll_column].shift(lag+1).rolling(period).agg(agg_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d22ea897",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_short = ['Wspd', 'Wdir', 'Etmp', 'Itmp', 'Ndir', 'Pab1', 'Pab2', 'Pab3', 'Prtv', 'Patv']\n",
    "feature_column_long = ['DayofWeek', 'Hour', 'MinuteofDay']\n",
    "target_column = ['Patv', 'is_valid'] # Patv is Wind Power average -> value to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58710846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wspd_lag6_roll6_mean',\n",
       " 'Wspd_lag6_roll6_max',\n",
       " 'Wspd_lag144_roll6_mean',\n",
       " 'Wspd_lag144_roll6_max']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "318695ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_short += feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ce80626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5818cda5",
   "metadata": {},
   "source": [
    "#### get column index (target, short, long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be55de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_idx = [data.columns.get_loc(c) for c in target_column]\n",
    "feature_column_idx_short = [data.columns.get_loc(c) for c in feature_column_short]\n",
    "feature_column_idx_long = [data.columns.get_loc(c) for c in feature_column_long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e29422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d83eaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_columns='Day' \n",
    "mode='train'\n",
    "train_sequence_length = 2 * 24 * 6  # 2 weeks (6 open days per week)\n",
    "predict_sequence_length = 2 * 24 * 6\n",
    "strides= 1\n",
    "max_lags=288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1489f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get end of the datasets Index (size = predicted Size expected)\n",
    "def func(data):\n",
    "    return data.tail(predict_sequence_length - 1).index.tolist()\n",
    "# get beginning of dataset index\n",
    "def func2(data):\n",
    "    return data.head(max(train_sequence_length, max_lags) + 1).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8f88240",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca0be7",
   "metadata": {},
   "source": [
    "#### Calculate IDX (TRAIN) to be removed \n",
    "\n",
    "=> Does not have enough pre values for rolling or next values for predicted size test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01ede61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all index matching with Day = training days\n",
    "all_idx = data.loc[data[day_columns].isin(train_days)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03fde27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.groupby(['TurbID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dfa4676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>...</th>\n",
       "      <th>start_time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>MinuteofDay</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>Wspd_lag6_roll6_mean</th>\n",
       "      <th>Wspd_lag6_roll6_max</th>\n",
       "      <th>Wspd_lag144_roll6_mean</th>\n",
       "      <th>Wspd_lag144_roll6_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.234690</td>\n",
       "      <td>0.571311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>0.234690</td>\n",
       "      <td>0.571311</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>0.238494</td>\n",
       "      <td>0.571653</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.244199</td>\n",
       "      <td>0.571927</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:30</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>0.237733</td>\n",
       "      <td>0.572232</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:40</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692240</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.184481</td>\n",
       "      <td>0.570116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692241</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>0.184481</td>\n",
       "      <td>0.570116</td>\n",
       "      <td>30.83</td>\n",
       "      <td>30.59</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692242</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>0.164701</td>\n",
       "      <td>0.571508</td>\n",
       "      <td>30.79</td>\n",
       "      <td>30.58</td>\n",
       "      <td>-4.94</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692243</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.161658</td>\n",
       "      <td>0.571608</td>\n",
       "      <td>30.77</td>\n",
       "      <td>30.50</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:30</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692244</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>0.160517</td>\n",
       "      <td>0.571334</td>\n",
       "      <td>30.72</td>\n",
       "      <td>30.49</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>1 00:40</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TurbID  Day Tmstamp      Wspd      Wdir   Etmp   Itmp   Ndir  Pab1  \\\n",
       "0             1    1   00:00  0.234690  0.571311    NaN    NaN    NaN   NaN   \n",
       "1             1    1   00:10  0.234690  0.571311  30.73  41.80  25.92  1.00   \n",
       "2             1    1   00:20  0.238494  0.571653  30.60  41.63  20.91  1.00   \n",
       "3             1    1   00:30  0.244199  0.571927  30.52  41.52  20.91  1.00   \n",
       "4             1    1   00:40  0.237733  0.572232  30.49  41.38  20.91  1.00   \n",
       "...         ...  ...     ...       ...       ...    ...    ...    ...   ...   \n",
       "4692240     134    1   00:00  0.184481  0.570116    NaN    NaN    NaN   NaN   \n",
       "4692241     134    1   00:10  0.184481  0.570116  30.83  30.59   7.30  0.23   \n",
       "4692242     134    1   00:20  0.164701  0.571508  30.79  30.58  -4.94  0.03   \n",
       "4692243     134    1   00:30  0.161658  0.571608  30.77  30.50  -4.95  0.04   \n",
       "4692244     134    1   00:40  0.160517  0.571334  30.72  30.49  -4.95  0.02   \n",
       "\n",
       "         Pab2  ...  start_time  Hour  Minute MinuteofDay  DayofWeek  is_valid  \\\n",
       "0         NaN  ...     1 00:00     0       0         0.0          0         1   \n",
       "1        1.00  ...     1 00:10     0      10         1.0          0         1   \n",
       "2        1.00  ...     1 00:20     0      20         2.0          0         1   \n",
       "3        1.00  ...     1 00:30     0      30         3.0          0         1   \n",
       "4        1.00  ...     1 00:40     0      40         4.0          0         1   \n",
       "...       ...  ...         ...   ...     ...         ...        ...       ...   \n",
       "4692240   NaN  ...     1 00:00     0       0         0.0          0         1   \n",
       "4692241  0.23  ...     1 00:10     0      10         1.0          0         1   \n",
       "4692242  0.03  ...     1 00:20     0      20         2.0          0         1   \n",
       "4692243  0.04  ...     1 00:30     0      30         3.0          0         1   \n",
       "4692244  0.02  ...     1 00:40     0      40         4.0          0         1   \n",
       "\n",
       "         Wspd_lag6_roll6_mean  Wspd_lag6_roll6_max  Wspd_lag144_roll6_mean  \\\n",
       "0                         NaN                  NaN                     NaN   \n",
       "1                         NaN                  NaN                     NaN   \n",
       "2                         NaN                  NaN                     NaN   \n",
       "3                         NaN                  NaN                     NaN   \n",
       "4                         NaN                  NaN                     NaN   \n",
       "...                       ...                  ...                     ...   \n",
       "4692240                   NaN                  NaN                     NaN   \n",
       "4692241                   NaN                  NaN                     NaN   \n",
       "4692242                   NaN                  NaN                     NaN   \n",
       "4692243                   NaN                  NaN                     NaN   \n",
       "4692244                   NaN                  NaN                     NaN   \n",
       "\n",
       "         Wspd_lag144_roll6_max  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "...                        ...  \n",
       "4692240                    NaN  \n",
       "4692241                    NaN  \n",
       "4692242                    NaN  \n",
       "4692243                    NaN  \n",
       "4692244                    NaN  \n",
       "\n",
       "[670 rows x 23 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a69f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e23c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoove last indexes from data (not enough next val to match with predicted size expected)\n",
    "dropidx = joblib.Parallel(cpu_count)(joblib.delayed(func)(group) for name, group in data_grouped)\n",
    "dropidx = list(itertools.chain(*dropidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "471394aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoove First indexes from data not enough values for the rolling features to be calculated\n",
    "dropidx2 = joblib.Parallel(cpu_count)(joblib.delayed(func2)(group) for name, group in data_grouped)\n",
    "dropidx2 = list(itertools.chain(*dropidx2))      \n",
    "dropidx += dropidx2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f1ca521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoove Drop index calculated from the whole list of Training index\n",
    "train_idx  = sorted(list(set(all_idx) - set(dropidx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780b2c5",
   "metadata": {},
   "source": [
    "#### Reader object used to store and give access to Training data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "012a8d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eee6ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_aggs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1526376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_reader = DataReader(\n",
    "        data, \n",
    "        train_sequence_length, \n",
    "        predict_sequence_length, \n",
    "        idx=train_idx, \n",
    "        target_aggs=target_aggs, \n",
    "        target_column_idx=target_column_idx, \n",
    "        feature_column_idx_short=feature_column_idx_short, \n",
    "        feature_column_idx_long=feature_column_idx_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b7550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "        train_data_reader, \n",
    "        len(feature_column_short), \n",
    "        len(feature_column_long))(batch_size=1024, shuffle=True, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021b092",
   "metadata": {},
   "source": [
    "#### Calculate IDX (VALID) to be removed \n",
    "\n",
    "=> Does not have enough pre values for rolling or next values for predicted size test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1272a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all index matching with Day = valid days\n",
    "all_idx = data.loc[data[day_columns].isin(valid_days)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a053dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.groupby(['TurbID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61cf5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoove last indexes from data (not enough next val to match with predicted size expected)\n",
    "dropidx = joblib.Parallel(cpu_count)(joblib.delayed(func)(group) for name, group in data_grouped)\n",
    "dropidx = list(itertools.chain(*dropidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a889bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = sorted(list(set(all_idx) - set(dropidx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37a0fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_reader = DataReader(\n",
    "    data, \n",
    "    train_sequence_length, \n",
    "    predict_sequence_length, \n",
    "    idx=val_idx, \n",
    "    target_aggs=target_aggs, \n",
    "    target_column_idx=target_column_idx, \n",
    "    feature_column_idx_short=feature_column_idx_short, \n",
    "    feature_column_idx_long=feature_column_idx_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1532f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_loader = DataLoader(\n",
    "    valid_data_reader, \n",
    "    len(feature_column_short), \n",
    "    len(feature_column_long))(batch_size=1024, shuffle=True, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2db5eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = data.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62f200d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3434554 250982 250982\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_reader), len(valid_data_reader), len(valid_df)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a70c5",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d14d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(use_model, train_sequence_length, predict_sequence_length=288, target_aggs=1, short_feature_nums=10, long_feature_nums=1):\n",
    "    inputs = (\n",
    "        Input([1]),\n",
    "        Input([train_sequence_length, short_feature_nums]),  # raw feature numbers\n",
    "        Input([train_sequence_length+predict_sequence_length, long_feature_nums])  # long feature\n",
    "        )\n",
    "    teacher_inputs = Input([predict_sequence_length//target_aggs, 1])\n",
    "\n",
    "    ts_inputs = KDD(train_sequence_length, predict_sequence_length)(inputs)\n",
    "    outputs = build_tfts_model(\n",
    "        use_model=use_model, \n",
    "        predict_sequence_length=predict_sequence_length//target_aggs, \n",
    "        custom_model_params=cfg.custom_model_params)(ts_inputs, teacher_inputs)\n",
    "\n",
    "    model = tf.keras.Model(inputs={'inputs':inputs, 'teacher': teacher_inputs}, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a93dee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(use_model, train_sequence_length, predict_sequence_length=288, target_aggs=1, short_feature_nums=10, long_feature_nums=1):\n",
    "    inputs = (\n",
    "        Input([1]),\n",
    "        Input([train_sequence_length, short_feature_nums]),  # raw feature numbers\n",
    "        Input([train_sequence_length+predict_sequence_length, long_feature_nums])  # long feature\n",
    "        )\n",
    "    teacher_inputs = Input([predict_sequence_length//target_aggs, 1])\n",
    "\n",
    "    ts_inputs = KDD(train_sequence_length, predict_sequence_length)(inputs)\n",
    "    outputs = build_tfts_model(\n",
    "        use_model=use_model, \n",
    "        predict_sequence_length=predict_sequence_length//target_aggs, \n",
    "        custom_model_params=cfg.custom_model_params)(ts_inputs, teacher_inputs)\n",
    "\n",
    "    model = tf.keras.Model(inputs={'inputs':inputs, 'teacher': teacher_inputs}, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7ba7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053b950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81984250",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_model = 'bert' # Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6939ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_feature_nums=len(feature_column_short)\n",
    "long_feature_nums=len(feature_column_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f61b1",
   "metadata": {},
   "source": [
    "#### Define Model Format Inputs\n",
    "\n",
    "=> TO DO ++ = Describe Each part of inputs usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61828de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = (\n",
    "        Input([1]),\n",
    "        Input([train_sequence_length, short_feature_nums]),  # raw feature numbers\n",
    "        Input([train_sequence_length+predict_sequence_length, long_feature_nums])  # long feature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1a7129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_inputs = Input([predict_sequence_length//target_aggs, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d630f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ts_inputs = KDD(train_sequence_length, predict_sequence_length)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "559089cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF = KDD object\n",
    "_, raw, raw_long  = inputs  # feature is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "292a382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 14) dtype=float32 (created by layer 'input_2')>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a767fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 576, 3) dtype=float32 (created by layer 'input_3')>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b1b4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Row (14 features) in 2 (10 features / 4 features) \n",
    "raw, manual = tf.split(raw, [10, tf.shape(raw)[-1]-10], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cadace7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 10) dtype=float32 (created by layer 'tf.split')>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw  # Original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4503bb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 4) dtype=float32 (created by layer 'tf.split')>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual # Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517edd1",
   "metadata": {},
   "source": [
    "#### Split Raw features (10) in 10 different layers (explicit for wind_speed, wind dir, active power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b796987",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed, wind_dir, _, _, _, _, _, _, _, active_power = tf.split(raw, 10, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b087f9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 1) dtype=float32 (created by layer 'tf.split_1')>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f489f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 1) dtype=float32 (created by layer 'tf.split_1')>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f6e610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 1) dtype=float32 (created by layer 'tf.split_1')>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1b944b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = tf.where(tf.math.is_nan(manual), tf.zeros_like(manual), manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8ab429d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 4) dtype=float32 (created by layer 'tf.where')>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed97bd",
   "metadata": {},
   "source": [
    "#### Split Manual features (3) in 3 different layers (explicit for day_of_week, hour_feature, minute_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9c45dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week, hour_feature, minute_of_day = tf.split(raw_long, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89cdb0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 576, 1) dtype=float32 (created by layer 'tf.split_2')>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a593e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization ?\n",
    "hour_feature = hour_feature / 23 - 0.5       # 24 hours per day                           (-> [-0.5 : 0.5])\n",
    "minute_of_day = minute_of_day / 143 - 0.5    # 6 periods of 10 mn per hour (144/6/24 = 1) (-> [-0.5 : 0.5])\n",
    "day_of_week = day_of_week / 6 - 0.5          # 6 days per week                            (-> [-0.5 : 0.5])\n",
    "\n",
    "# Remark YLE -> This representation hides the fact that hours are continuous (23h and 00h are close but represented far here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "059a6cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 576, 1) dtype=float32 (created by layer 'tf.math.subtract_1')>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d4a47",
   "metadata": {},
   "source": [
    "#### Create decode layers with only Predict Sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee389afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, decoder_hour_feature = tf.split(hour_feature, [train_sequence_length, predict_sequence_length], axis=1)       \n",
    "_, decoder_minute_feature = tf.split(minute_of_day, [train_sequence_length, predict_sequence_length], axis=1)\n",
    "_, decoder_day_feature = tf.split(day_of_week, [train_sequence_length, predict_sequence_length], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1228d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 1) dtype=float32 (created by layer 'tf.split_3')>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_hour_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05e59d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_features = tf.concat([wind_speed, wind_dir], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e272bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 2) dtype=float32 (created by layer 'tf.concat')>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode features with 288 timesteps Window as past values (2 weeks * 6 days * 24 hours)\n",
    "encoder_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "006e39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder features with 3 features + 288 timesteps Window as future predicted values(2 weeks * 6 days * 24 hours)\n",
    "decoder_features = tf.concat([decoder_hour_feature, decoder_minute_feature, decoder_day_feature], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98c287e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_features = tf.cast(decoder_features, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d2716",
   "metadata": {},
   "source": [
    "#### All inputs layers have been created :\n",
    "\n",
    "- Encoder : Windspeed & Windirection features * 288 Timesteps Windows (last past values)\n",
    "- Decoder : Day, Hour, Minute features * 288 Timesteps Windows (Future values to predict)\n",
    "- active_power : Target layer to predict (WindPower) for the future 288 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f5d376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape Encoder :  (None, 288, 2)\n",
      "Feature shape Decoder :  (None, 288, 3)\n",
      "Target shape :  (None, 288, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Feature shape Encoder : ', encoder_features.shape)\n",
    "print('Feature shape Decoder : ', decoder_features.shape)\n",
    "print('Target shape : ', active_power.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02d7da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_inputs = active_power, encoder_features, decoder_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b310b6",
   "metadata": {},
   "source": [
    "#### Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0dfdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_params = {\n",
    "    'n_encoder_layers': 1,\n",
    "    'use_token_embedding': False,\n",
    "    'attention_hidden_sizes': 32*1,\n",
    "    'num_heads': 1,\n",
    "    'attention_dropout': 0.,\n",
    "    'ffn_hidden_sizes': 32,\n",
    "    'ffn_filter_sizes': 32,  # should be same with attention_hidden_sizes\n",
    "    'ffn_dropout': 0.,\n",
    "    'layer_postprocess_dropout': 0.,\n",
    "    'skip_connect': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2819a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfts_model(use_model, predict_sequence_length, custom_model_params=None):\n",
    "    if use_model.lower() == \"seq2seq\":\n",
    "        Model = Seq2seq(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    elif use_model.lower() == \"wavenet\":\n",
    "        Model = WaveNet(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    elif use_model.lower() == \"transformer\":\n",
    "        Model = Transformer(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    elif use_model.lower() == \"bert\":\n",
    "        Model = Bert(predict_sequence_length=predict_sequence_length, custom_model_params=custom_model_params)\n",
    "    else:\n",
    "        raise ValueError(\"unsupported use_model of {} yet\".format(use_model))\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4bdfdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 288, 1) dtype=float32 (created by layer 'tf.split_1')>,\n",
       " <KerasTensor: shape=(None, 288, 2) dtype=float32 (created by layer 'tf.concat')>,\n",
       " <KerasTensor: shape=(None, 288, 3) dtype=float32 (created by layer 'tf.cast')>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a644331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 1) dtype=float32 (created by layer 'input_4')>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2b326d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = build_tfts_model(\n",
    "        use_model=use_model, \n",
    "        predict_sequence_length=predict_sequence_length//target_aggs, \n",
    "        custom_model_params=custom_model_params)(ts_inputs, teacher_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b81d5eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 288, 1) dtype=float32 (created by layer 'tf.expand_dims')>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee8fe80",
   "metadata": {},
   "source": [
    "#### Custom Loss fonction (based on Mean Square Error) used for the Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f29a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs={'inputs':inputs, 'teacher': teacher_inputs}, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f64a7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):   \n",
    "    true, mask = tf.split(y_true, 2, axis=-1)   \n",
    "    mask = tf.cast(mask, dtype=tf.float32)  \n",
    "    true *= mask\n",
    "    y_pred *= mask\n",
    "    rmse_score = tf.math.sqrt(tf.reduce_mean(tf.square(true - y_pred)) + 1e-9)\n",
    "    return rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4d666ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-3)\n",
    "loss_fn = custom_loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "677e9d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_1')>,\n",
       " <KerasTensor: shape=(None, 288, 14) dtype=float32 (created by layer 'input_2')>,\n",
       " <KerasTensor: shape=(None, 576, 3) dtype=float32 (created by layer 'input_3')>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9109b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = KerasTrainer(model, loss_fn=loss_fn, optimizer=optimizer, strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d385d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "        'n_epochs': 3,\n",
    "        'batch_size': 1024,\n",
    "        'learning_rate': 5e-3,\n",
    "        'verbose': 1,\n",
    "        'checkpoint': ModelCheckpoint(\n",
    "            'checkpoint/nn_{}.h5'.format(use_model), \n",
    "            monitor='val_loss', \n",
    "            save_weights_only=True, \n",
    "            save_best_only=False, \n",
    "            verbose=1),      \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "beee09d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "coucou",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoucou\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: coucou"
     ]
    }
   ],
   "source": [
    "raise Exception('coucou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be7bcf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'inputs': (TensorSpec(shape=(1024,), dtype=tf.int32, name=None), TensorSpec(shape=(1024, 288, 14), dtype=tf.float32, name=None), TensorSpec(shape=(1024, 576, 3), dtype=tf.float32, name=None)), 'teacher': TensorSpec(shape=(1024, 288, 1), dtype=tf.float32, name=None)}, TensorSpec(shape=(1024, 288, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader.get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_data_loader, valid_dataset=valid_data_loader, **fit_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "05b0372f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'inputs': (TensorSpec(shape=(1024,), dtype=tf.int32, name=None), TensorSpec(shape=(1024, 288, 14), dtype=tf.float32, name=None), TensorSpec(shape=(1024, 576, 3), dtype=tf.float32, name=None)), 'teacher': TensorSpec(shape=(1024, 288, 1), dtype=tf.float32, name=None)}, TensorSpec(shape=(1024, 288, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1261377d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TakeDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TakeDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d3c43cd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PrefetchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_data_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'PrefetchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dataset_train = valid_data_loader[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e1149f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 288, 14)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['input_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  ()                   0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)          [(None, 288, 10),    0           ['input_2[0][0]',                \n",
      "                                 (None, 288, 4)]                  'tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)        [(None, 288, 1),     0           ['tf.split[0][0]']               \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1),                                                  \n",
      "                                 (None, 288, 1)]                                                  \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 288, 2)       0           ['tf.split_1[0][0]',             \n",
      "                                                                  'tf.split_1[0][1]']             \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 288, 3)       0           ['tf.split_1[0][9]',             \n",
      "                                                                  'tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " token_embedding (TokenEmbeddin  (None, 288, 32)     96          ['tf.concat_2[0][0]']            \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " encoder (Encoder)              (None, 288, 32)      5312        ['token_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 32)          0           ['encoder[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32)           0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          16896       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            multiple             0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         525312      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 288)          295200      ['dropout_1[1][0]']              \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 576, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 288, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 288, 1)       0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 842,816\n",
      "Trainable params: 842,816\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ebc4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
