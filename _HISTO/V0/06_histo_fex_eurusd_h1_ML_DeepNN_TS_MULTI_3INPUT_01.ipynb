{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b2e147",
   "metadata": {},
   "source": [
    "# Applications d'algo Deep Learning (NN) adaptés aux Time Series\n",
    "\n",
    "Il existe plusieurs types de modèles adaptés aux Time Series. Leur particularité est de ne pas utiliser simplement les données comme des évenements indépendants mais de conserver une \"mémoire\" des évenements précédents pour mieux analyser un instant T.\n",
    "\n",
    "Ceci est utile notamment pour trouver des pattern de tendance à terme. Voici les principaux modèles :\n",
    "- RNN  : Recurrent Neuronal Network\n",
    "- LSTM : Long Short-Term Memory\n",
    "- GRU  : Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a4b56",
   "metadata": {},
   "source": [
    "# Combinaison multi-input\n",
    "\n",
    "On a vu précédemment que les réseaux GRU ou LSTM donnaient les moins mauvais résultats (insufffisant). Les 2 utilisent des fenêtres d'inervalle de temps pour prédire un instant T à partir de plusieurs observations passés. Le GRU plutôt sur des grandes fenêtres, un peu plus courtes pour le LSTM.\n",
    "\n",
    "En analyse technique on va souvent utiliser plusieurs types de fenêtre d'interval (nb observations passées) simultanément. C'est ce qu'on va essayer de reproduire ici avec des réseaux combinants plusieurs input.\n",
    "\n",
    "Voici les 2 éléments qu'on va vouloir intégrer :\n",
    "- Information de base de l'observation (ellles sont noyés dans les observations de la fenêtre) donc on veut ici les répeter pour qu'elles soient \"conservées\"/non transformés.\n",
    "- Utilisation en parallèle de plusieurs layers (LSTM/GRU) en entrée qui vont pré-analyser les données avec fenêtrage mais sur des inetrvals de temps différents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592727c",
   "metadata": {},
   "source": [
    "## Constitution des datasets\n",
    "\n",
    "On va constituer 3 datasets différents avec une profondeur différente (nombre de variables) afin de pouvoir comparer notamment l'impact des indicateurs sur la qualité du résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bdb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f26a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d15cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8890cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Convolution1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.layers import LSTM, GRU, TimeDistributed, Conv1D, ConvLSTM2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5578163",
   "metadata": {},
   "source": [
    "### Datasets : EURUSD H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47d232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = 'postgresql://postgres:Juw51000@localhost/tradingIA'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f676f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>mopen</th>\n",
       "      <th>mclose</th>\n",
       "      <th>mhigh</th>\n",
       "      <th>mlow</th>\n",
       "      <th>mvolume</th>\n",
       "      <th>mspread</th>\n",
       "      <th>ima</th>\n",
       "      <th>ima2</th>\n",
       "      <th>ima4</th>\n",
       "      <th>...</th>\n",
       "      <th>istos4</th>\n",
       "      <th>imom</th>\n",
       "      <th>imom2</th>\n",
       "      <th>imom4</th>\n",
       "      <th>rProfitBuy</th>\n",
       "      <th>rSwapBuy</th>\n",
       "      <th>rProfitBTrigger</th>\n",
       "      <th>rProfitSell</th>\n",
       "      <th>rSwapSell</th>\n",
       "      <th>rProfitSTrigger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946861200</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>194</td>\n",
       "      <td>50</td>\n",
       "      <td>1.008242</td>\n",
       "      <td>1.007963</td>\n",
       "      <td>1.006779</td>\n",
       "      <td>...</td>\n",
       "      <td>70.129870</td>\n",
       "      <td>100.536033</td>\n",
       "      <td>100.615935</td>\n",
       "      <td>100.565982</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-3.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>946864800</td>\n",
       "      <td>1.0129</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>1.0141</td>\n",
       "      <td>1.0120</td>\n",
       "      <td>113</td>\n",
       "      <td>50</td>\n",
       "      <td>1.008733</td>\n",
       "      <td>1.008175</td>\n",
       "      <td>1.006973</td>\n",
       "      <td>...</td>\n",
       "      <td>72.331461</td>\n",
       "      <td>100.675340</td>\n",
       "      <td>100.815515</td>\n",
       "      <td>100.495688</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>946868400</td>\n",
       "      <td>1.0140</td>\n",
       "      <td>1.0171</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0134</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>1.009517</td>\n",
       "      <td>1.008588</td>\n",
       "      <td>1.007215</td>\n",
       "      <td>...</td>\n",
       "      <td>76.041667</td>\n",
       "      <td>101.073239</td>\n",
       "      <td>101.002979</td>\n",
       "      <td>100.902778</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>946872000</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>1.0175</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>1.010350</td>\n",
       "      <td>1.008958</td>\n",
       "      <td>1.007462</td>\n",
       "      <td>...</td>\n",
       "      <td>78.688525</td>\n",
       "      <td>100.872410</td>\n",
       "      <td>100.962493</td>\n",
       "      <td>100.882411</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>946875600</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>1.0164</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>1.010975</td>\n",
       "      <td>1.009296</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>...</td>\n",
       "      <td>78.511530</td>\n",
       "      <td>100.703249</td>\n",
       "      <td>100.893123</td>\n",
       "      <td>100.813089</td>\n",
       "      <td>-2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       epoch   mopen  mclose   mhigh    mlow  mvolume  mspread       ima  \\\n",
       "0  946861200  1.0073  1.0128  1.0132  1.0073      194       50  1.008242   \n",
       "1  946864800  1.0129  1.0137  1.0141  1.0120      113       50  1.008733   \n",
       "2  946868400  1.0140  1.0171  1.0173  1.0134      149       50  1.009517   \n",
       "3  946872000  1.0170  1.0175  1.0190  1.0170      214       50  1.010350   \n",
       "4  946875600  1.0173  1.0167  1.0177  1.0164      162       50  1.010975   \n",
       "\n",
       "       ima2      ima4  ...     istos4        imom       imom2       imom4  \\\n",
       "0  1.007963  1.006779  ...  70.129870  100.536033  100.615935  100.565982   \n",
       "1  1.008175  1.006973  ...  72.331461  100.675340  100.815515  100.495688   \n",
       "2  1.008588  1.007215  ...  76.041667  101.073239  101.002979  100.902778   \n",
       "3  1.008958  1.007462  ...  78.688525  100.872410  100.962493  100.882411   \n",
       "4  1.009296  1.007677  ...  78.511530  100.703249  100.893123  100.813089   \n",
       "\n",
       "   rProfitBuy  rSwapBuy  rProfitBTrigger  rProfitSell  rSwapSell  \\\n",
       "0        3.64       0.0               TO        -3.07        0.0   \n",
       "1        2.56       0.0               TO        -3.15        0.0   \n",
       "2       -0.10       0.0               TO        -0.88        0.0   \n",
       "3       -2.36       0.0               TO         1.38        0.0   \n",
       "4       -2.95       0.0               SL         5.74        0.0   \n",
       "\n",
       "   rProfitSTrigger  \n",
       "0               SL  \n",
       "1               SL  \n",
       "2               TO  \n",
       "3               TO  \n",
       "4               TP  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"select * from fex_eurusd_h1\", conn);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e0718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['targetBuy'] = df['rProfitBuy'] + df['rSwapBuy']\n",
    "df['targetSell'] = df['rProfitSell'] + df['rSwapSell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06a3339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145559, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNotNa = df[df['rProfitBTrigger'].notna()]\n",
    "dfCleanRow = dfNotNa[dfNotNa['epoch'] < 1690484400]\n",
    "dfClean = dfCleanRow.drop(['rProfitBuy', 'rSwapBuy', 'rProfitSell', 'rSwapSell', 'rProfitSTrigger', 'rProfitBTrigger'], axis=1)\n",
    "dfClean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6890a",
   "metadata": {},
   "source": [
    "### Transposition en problème de classification binaire\n",
    "\n",
    "On peut simplifier la question de base qui est de savoir quel est le moment du profit (Buy/Sell) en question binaire, à savoir est-ce que le trade à un instant T (Buy et Sell) entrainera une perte (0) ou un gain (1) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e27e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin = dfClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03ecad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145559, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanBin['targetProfitBuy'] = dfCleanBin['targetBuy'].apply(lambda x: 1 if x > 0 else 0)\n",
    "dfCleanBin['targetProfitSell'] = dfCleanBin['targetSell'].apply(lambda x: 1 if x > 0 else 0)\n",
    "dfCleanBin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baa6c763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33065.310000000005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetBuy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "285bc1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37148510226093884"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetProfitBuy']) / dfCleanBin.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5425ca90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32935.02000000026"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetSell'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae040253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37439801042876086"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetProfitSell']) / dfCleanBin.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06db9b96",
   "metadata": {},
   "source": [
    "Qu'il s'agisse des Profits Buy ou Sell on est à environ 37% de target Profit pour 63% de perte. Les classes sont donc plutôt équilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea402816",
   "metadata": {},
   "source": [
    "### Glissement des valeurs Target (prévision)\n",
    "\n",
    "Pour la prévision les valeurs à prédire (profit du trade) sont les valeurs qui concernent la periode à venir du trade (T+1) en fonction des features observées sur la periode actuelle (T). On doit donc glisser les valeurs de Target de T+1 vers T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc2b9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin['targetProfitBuy'] = dfCleanBin['targetProfitBuy'].shift(-1)\n",
    "dfCleanBin['targetProfitSell'] = dfCleanBin['targetProfitSell'].shift(-1)\n",
    "dfCleanBin['targetSell'] = dfCleanBin['targetSell'].shift(-1)\n",
    "dfCleanBin['targetBuy'] = dfCleanBin['targetBuy'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ca4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin = dfCleanBin[dfCleanBin['targetProfitSell'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12957051",
   "metadata": {},
   "source": [
    "### Transformation du prix d'ouverture\n",
    "\n",
    "Le prix d'ouverture T est finalement le prix de clôture T-1 (avec possible légère correction), il n'est donc pas primordial.\n",
    "On aimerait mieux peut-être visualiser facilement le sens de tendance de la periode (Prix cloture - Prix ouverture) plus révélateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f00fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin['evol'] = dfCleanBin['mclose'] - dfCleanBin['mopen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d9f9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    145558.000000\n",
       "mean          0.000004\n",
       "std           0.001462\n",
       "min          -0.024800\n",
       "25%          -0.000600\n",
       "50%           0.000000\n",
       "75%           0.000600\n",
       "max           0.030200\n",
       "Name: evol, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanBin['evol'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aac8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin.set_index('epoch', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dbd21",
   "metadata": {},
   "source": [
    "#### Dataset basis\n",
    "Ce dataset ne va comporfter que les données brutes (en plus des target) sans aucun indicateur technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d0eaa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBasisB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy']]\n",
    "dfBasisS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb0548",
   "metadata": {},
   "source": [
    "#### Dataset intermediate low\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi que la version des indicateurs sur la plus courte periode de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "399d5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntLowB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd', 'istos', 'imom']]\n",
    "dfIntLowS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd', 'istos', 'imom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb372ccd",
   "metadata": {},
   "source": [
    "#### Dataset intermediate Medium\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi que la version des indicateurs sur la periode de calcul intermediaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af77f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntMedB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima2', 'iatr2', 'irsi2', 'imacd2', 'istos2', 'imom2']]\n",
    "dfIntMedS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima2', 'iatr2', 'irsi2', 'imacd2', 'istos2', 'imom2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca9bb5",
   "metadata": {},
   "source": [
    "#### Dataset intermediate High\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi que la version des indicateurs sur la plus longue periode de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49f530c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntHigB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima4', 'iatr4', 'irsi4', 'imacd4', 'istos4', 'imom4']]\n",
    "dfIntHigS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima4', 'iatr4', 'irsi4', 'imacd4', 'istos4', 'imom4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb0eb3",
   "metadata": {},
   "source": [
    "#### Dataset Complet\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi tous les indicateurs sur toutes les periodes de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9dfd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFullB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd','ima2', 'iatr2', 'irsi2', 'imacd2','ima4', 'iatr4', 'irsi4', 'imacd4',\n",
    "                   'istos', 'istos2', 'istos4', 'imom', 'imom2', 'imom4']]\n",
    "dfFullS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd','ima2', 'iatr2', 'irsi2', 'imacd2','ima4', 'iatr4', 'irsi4', 'imacd4',\n",
    "                   'istos', 'istos2', 'istos4', 'imom', 'imom2', 'imom4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ecc91",
   "metadata": {},
   "source": [
    "## Applications des Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bfb79",
   "metadata": {},
   "source": [
    "#### Utilisation du modele de base : dfBasisB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ab1dc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145558, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBasisB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487706f3",
   "metadata": {},
   "source": [
    "#### Definition des datsests de Features / Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69cdbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfBasisB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a488a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTarget = df['targetProfitBuy']\n",
    "dfFeatures = df.drop(columns=['targetProfitBuy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce7098",
   "metadata": {},
   "source": [
    "#### Separation du Dataset Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d98eec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTestDatasets(dfFeatures, dfTarget, testSize=.2):\n",
    "    rs = ShuffleSplit(n_splits=1, test_size=testSize)\n",
    "    train_index, test_index = next(rs.split(dfFeatures, dfTarget)) \n",
    "    dX_train, dX_test = dfFeatures.iloc[train_index], dfFeatures.iloc[test_index] \n",
    "    dy_train, dy_test = dfTarget.iloc[train_index], dfTarget.iloc[test_index]\n",
    "    return dX_train, dX_test, dy_train, dy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fbf994",
   "metadata": {},
   "source": [
    "Split into (Train + Valid) / Test datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "377e482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeaturesT, dX_test, dfTargetT, dy_test = getTrainTestDatasets(dfFeatures, dfTarget, .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a21933",
   "metadata": {},
   "source": [
    "Split into Train / Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8aed2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_train, dX_val, dy_train, dy_val = getTrainTestDatasets(dfFeaturesT, dfTargetT, .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd430d9b",
   "metadata": {},
   "source": [
    "#### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7c513ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(dX_train)\n",
    "X_test = scaler.transform(dX_test)\n",
    "X_val = scaler.transform(dX_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60269a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dy_train.to_numpy()\n",
    "y_test = dy_test.to_numpy()\n",
    "y_val = dy_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22067119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104801, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9fe271",
   "metadata": {},
   "source": [
    "#### Spécificité LSTM / GRU : Separation des données en sous-ensembles\n",
    "\n",
    "Les LSTM travaillent par lots (sous-ensembles) qui déterminent pour une instance donné quelles sont les instances précédentes qui doivent lui être associées.\n",
    "\n",
    "Dans le contexte du trading on va donner pour chaque extrait de données à un instant T un nombre n (paramètre) d'extraits qui le précédent directement dans le temps [T-1 .... T-n], et qui vont être utilisés par LSTM pour comprendre la donnée à l'instant T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74471bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliSequencesWithSamples(xdata, ydata, lookback):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(xdata)):\n",
    "        if (i>=lookback-1): # Rows with not enough prev values cannot be taken\n",
    "            # gather input and output parts of the pattern\n",
    "            seq_x, seq_y = xdata[i+1-lookback:i+1, :], ydata[i]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)  \n",
    "    return(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae8f7b",
   "metadata": {},
   "source": [
    "## Calcul des scores et gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa490266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRandomProfit(dfCleanRow, target='targetBuy'):\n",
    "    profit = dfCleanRow[target].sum()\n",
    "    profitPerTrade = profit / len(dfCleanRow)\n",
    "    return profit, profitPerTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1a322ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProfit(dfCleanRow, dX_test, yTestLbk, pred, lookback=100, specificity=.8, target='targetBuy'):\n",
    "    [fpr, tpr, thr] = roc_curve(yTestLbk, pred, pos_label=1)\n",
    "    idx = np.max(np.where((1-fpr) > specificity)) \n",
    "    seuil = thr[idx]  \n",
    "    dfPred = pd.DataFrame(pred, columns = ['proba'])\n",
    "    #Get rows index with positive proba (proba > seuil)\n",
    "    xRows = dfPred[dfPred['proba']>seuil].index.to_numpy()\n",
    "    #Get matching index (epoch timestamp) from dX_test => Periods with proba > seuil\n",
    "    xEpochs = dX_test.iloc[lookback-1:,:].iloc[xRows].index.to_numpy()\n",
    "    dfCleanEpochIdx = dfCleanRow.set_index('epoch')\n",
    "    profit = dfCleanEpochIdx.loc[xEpochs][target].sum()\n",
    "    profitPerTrade = profit / len(xRows)\n",
    "    return profit, profitPerTrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfebcc",
   "metadata": {},
   "source": [
    "### Calcul des scores et gains (model 100 % aléatoire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2e8851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "profitRandom, profitPerTradeRandom = calculateRandomProfit(dfCleanRow, target='targetBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "166d213c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33065.30999999999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profitRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86ffe62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2271608763456742"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profitPerTradeRandom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf242d1",
   "metadata": {},
   "source": [
    "## Raw data + GRU\n",
    "\n",
    "NN will have two separate branch in parallel, combined in the end in a single branch :\n",
    "- 1 : Raw data for timestamp T (with BatchNormalisation only, to normalize data input)\n",
    "- 2 : GRU (Windowed period) : Analysis of Timestamp with his value and the N previous observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e34a2",
   "metadata": {},
   "source": [
    "Custom Metric functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9dd0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    import keras.backend as K\n",
    "    \"\"\"\n",
    "    Returns the mean absolute percentage error.\n",
    "    For examples on losses see:\n",
    "    https://github.com/keras-team/keras/blob/master/keras/losses.py\n",
    "    \"\"\"\n",
    "    return (K.abs(y_true - y_pred) / K.abs(y_pred)) * 100\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    import keras.backend as K\n",
    "    \"\"\"\n",
    "    Returns the Symmetric mean absolute percentage error.\n",
    "    For examples on losses see:\n",
    "    https://github.com/keras-team/keras/blob/master/keras/losses.py\n",
    "    \"\"\"\n",
    "    return (K.abs(y_pred - y_true) / ((K.abs(y_true) + K.abs(y_pred))))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7173b6",
   "metadata": {},
   "source": [
    "### Branche 1 : Raw Data\n",
    "\n",
    "Timestamp = T only (period data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89b4c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRawDataBranch(x_data):\n",
    "    inputRaw = Input(shape=(x_data.shape[1]))\n",
    "    return Model(inputs=inputRaw, outputs=inputRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcaf90a",
   "metadata": {},
   "source": [
    "### Branche 2 : WIndowed RNN analysed data \n",
    "\n",
    "Timestamps = T -> T-n (N last observations combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cefe0",
   "metadata": {},
   "source": [
    "#### Format Windowed data\n",
    "\n",
    "Expected format : 3D tensor (batch_size, timesteps, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70caad",
   "metadata": {},
   "source": [
    "####  Window 1 (LONG period : last 5 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42e51098",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback1 = 5 * 24     # Nb hours  (T-n) to look back for a time prediction (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fd8829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104682, 120, 6) (104682,)\n"
     ]
    }
   ],
   "source": [
    "xTrainLbk1, yTrainLbk1 = spliSequencesWithSamples(X_train, y_train, lookback1)\n",
    "print(xTrainLbk1.shape, yTrainLbk1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69fa72de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11526, 120, 6) (11526,)\n"
     ]
    }
   ],
   "source": [
    "xValLbk1, yValLbk1 = spliSequencesWithSamples(X_val, y_val, lookback1)\n",
    "print(xValLbk1.shape, yValLbk1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dafeec",
   "metadata": {},
   "source": [
    "####  Window 2 (MEDIUM period : last 24 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c1ed1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback2 = 1 * 24       # Nb hours  (T-n) to look back for a time prediction (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "825887cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104778, 24, 6) (104778,)\n"
     ]
    }
   ],
   "source": [
    "xTrainLbk2, yTrainLbk2 = spliSequencesWithSamples(X_train, y_train, lookback2)\n",
    "print(xTrainLbk2.shape, yTrainLbk2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5af5c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11622, 24, 6) (11622,)\n"
     ]
    }
   ],
   "source": [
    "xValLbk2, yValLbk2 = spliSequencesWithSamples(X_val, y_val, lookback2)\n",
    "print(xValLbk2.shape, yValLbk2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7de91",
   "metadata": {},
   "source": [
    "#### resized the Medium sized Windows nb rows according to long Windows size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "530e7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape3DRowsFrom3DWindowed(data3d, target2d, dataLong3d):\n",
    "    # Because they are windowed, each row of the 3D must have n previous item. \n",
    "    # So firsts N rows from 3D are not relevant (not enough prev items to match with 3D windowed dataset)\n",
    "    nbRowsIncomplete = data3d.shape[0] - dataLong3d.shape[0]\n",
    "    return data3d[nbRowsIncomplete:,:,:], target2d[nbRowsIncomplete:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "616aca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104682, 24, 6) (104682,)\n"
     ]
    }
   ],
   "source": [
    "X_trainSized3D, y_trainSized3D = reshape3DRowsFrom3DWindowed(xTrainLbk2, yTrainLbk2, xTrainLbk1)\n",
    "print(X_trainSized3D.shape, y_trainSized3D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3084e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11526, 24, 6) (11526,)\n"
     ]
    }
   ],
   "source": [
    "X_valSized3D, y_valSized3D = reshape3DRowsFrom3DWindowed(xValLbk2, yValLbk2, xValLbk1)\n",
    "print(X_valSized3D.shape, y_valSized3D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41685280",
   "metadata": {},
   "source": [
    "### Branche Combined \n",
    "\n",
    "Combined input branch and complete with Fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5b01cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeWindowedBranch(x_windowed_data):\n",
    "    inputWindow = Input(shape=(x_windowed_data.shape[1], x_windowed_data.shape[2]))\n",
    "    # GRU input : [timesteps, features] \n",
    "    mem1 = GRU(16, return_sequences = True, activation='tanh', kernel_initializer='TruncatedNormal')(inputWindow)    \n",
    "    mem2 = GRU(8,  return_sequences = False, activation='tanh', kernel_initializer='TruncatedNormal')(mem1)\n",
    "    return Model(inputs=inputWindow, outputs=mem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bf37430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCombinedIn3Model(x_data, x_windowed_long, x_windowed_medium) :\n",
    "    branche1 = createRawDataBranch(x_data)\n",
    "    branche2 = createTimeWindowedBranch(x_windowed_long)\n",
    "    branche3 = createTimeWindowedBranch(x_windowed_medium)\n",
    "    combined = layers.concatenate([branche1.output, branche2.output, branche3.output])\n",
    "    # Fully connected layers, with 1 final output for binary classification\n",
    "    d1 = Dense(16, name='Dense_1', activation='relu')(combined)\n",
    "    d2 = Dense(8, name='Dense_2', activation='relu')(d1)\n",
    "    d3 = Dense(1, name='Dense_3', activation='sigmoid')(d2)\n",
    "    model = Model(inputs=[branche1.input, branche2.input, branche3.input], outputs=d3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy' ,mape, smape])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e34c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCombined_Raw_GRU1_GRU2 = createCombinedIn3Model(X_train, xTrainLbk1, X_trainSized3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a10c598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 120, 6)]     0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 24, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 120, 16)      1152        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 24, 16)       1152        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 8)            624         ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, 8)            624         ['gru_2[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 22)           0           ['input_1[0][0]',                \n",
      "                                                                  'gru_1[0][0]',                  \n",
      "                                                                  'gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " Dense_1 (Dense)                (None, 16)           368         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " Dense_2 (Dense)                (None, 8)            136         ['Dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " Dense_3 (Dense)                (None, 1)            9           ['Dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,065\n",
      "Trainable params: 4,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelCombined_Raw_GRU1_GRU2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efcb316b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104801, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d21af90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104801,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a59f97a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104682, 120, 6)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainLbk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01531e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape2DRowsFrom3DWindowed(data2d, target2d, data3d):\n",
    "    # Because they are windowed, each row of the 3D must have n previous item. \n",
    "    # So firsts N rows from 2D are not relevant (not enough prev items to match with 3D windowed dataset)\n",
    "    nbRowsIncomplete = data2d.shape[0] - data3d.shape[0]\n",
    "    return data2d[nbRowsIncomplete:,:], target2d[nbRowsIncomplete:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9a295df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2D, y_train2D = reshape2DRowsFrom3DWindowed(X_train, y_train, xTrainLbk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55bb67b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104682, 6) (104682,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2D.shape, y_train2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58cae4",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0316110",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 4\n",
    "EPOCHS = 20\n",
    "LOOP = 2\n",
    "BATCH_SIZE = 32 # Default used my model.fit is 32\n",
    "steps_per_epoch = xTrainLbk1.shape[0] * LOOP / EPOCHS // BATCH_SIZE    # Split all data by Epochs ()\n",
    "validation_steps = xValLbk1.shape[0] // BATCH_SIZE                    # Take all validation data for validation on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee229345",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_WEIGHT = {0: 1, 1 : 2} # Use to counter unbalnced class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a297fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience = PATIENCE, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "603254eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val2D, y_val2D = reshape2DRowsFrom3DWindowed(X_val, y_val, xValLbk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6e8a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "327/327 [==============================] - 88s 232ms/step - loss: 0.9443 - accuracy: 0.4259 - mape: 95.9704 - smape: 74.7440 - val_loss: 0.7139 - val_accuracy: 0.4445 - val_mape: 94.5060 - val_smape: 73.4426\n",
      "Epoch 2/20\n",
      "327/327 [==============================] - 75s 231ms/step - loss: 0.9412 - accuracy: 0.4492 - mape: 95.4843 - smape: 74.2528 - val_loss: 0.7218 - val_accuracy: 0.4457 - val_mape: 92.8238 - val_smape: 72.9845\n",
      "Epoch 3/20\n",
      "327/327 [==============================] - 74s 227ms/step - loss: 0.9418 - accuracy: 0.4417 - mape: 94.2970 - smape: 73.9536 - val_loss: 0.7064 - val_accuracy: 0.4565 - val_mape: 95.6386 - val_smape: 73.7264\n",
      "Epoch 4/20\n",
      "327/327 [==============================] - 74s 227ms/step - loss: 0.9473 - accuracy: 0.4371 - mape: 93.9884 - smape: 73.1890 - val_loss: 0.7316 - val_accuracy: 0.3952 - val_mape: 91.1183 - val_smape: 72.5952\n",
      "Epoch 5/20\n",
      "327/327 [==============================] - 73s 224ms/step - loss: 0.9414 - accuracy: 0.4488 - mape: 93.7239 - smape: 73.3995 - val_loss: 0.7215 - val_accuracy: 0.4495 - val_mape: 93.0900 - val_smape: 73.0308\n",
      "Epoch 6/20\n",
      "327/327 [==============================] - 73s 224ms/step - loss: 0.9422 - accuracy: 0.4472 - mape: 94.2309 - smape: 73.6815 - val_loss: 0.7126 - val_accuracy: 0.4468 - val_mape: 94.5697 - val_smape: 73.4297\n",
      "Epoch 7/20\n",
      "327/327 [==============================] - 73s 224ms/step - loss: 0.9402 - accuracy: 0.4415 - mape: 94.7953 - smape: 74.1780 - val_loss: 0.7112 - val_accuracy: 0.4471 - val_mape: 94.8111 - val_smape: 73.4857\n",
      "Epoch 8/20\n",
      "327/327 [==============================] - 74s 226ms/step - loss: 0.9401 - accuracy: 0.4348 - mape: 94.2694 - smape: 74.0144 - val_loss: 0.7086 - val_accuracy: 0.4483 - val_mape: 95.4612 - val_smape: 73.6372\n",
      "Epoch 9/20\n",
      "327/327 [==============================] - 77s 235ms/step - loss: 0.9464 - accuracy: 0.4314 - mape: 94.5303 - smape: 73.6222 - val_loss: 0.7137 - val_accuracy: 0.4267 - val_mape: 94.2615 - val_smape: 73.4127\n",
      "Epoch 10/20\n",
      "327/327 [==============================] - 71s 216ms/step - loss: 0.9426 - accuracy: 0.4340 - mape: 93.7192 - smape: 73.4525 - val_loss: 0.7178 - val_accuracy: 0.4360 - val_mape: 93.5130 - val_smape: 73.1769\n",
      "Epoch 11/20\n",
      "327/327 [==============================] - 72s 222ms/step - loss: 0.9411 - accuracy: 0.4349 - mape: 94.7752 - smape: 74.0367 - val_loss: 0.7142 - val_accuracy: 0.4281 - val_mape: 94.1789 - val_smape: 73.3696\n",
      "Epoch 12/20\n",
      "327/327 [==============================] - 75s 230ms/step - loss: 0.9438 - accuracy: 0.4331 - mape: 94.0157 - smape: 73.5257 - val_loss: 0.7242 - val_accuracy: 0.4313 - val_mape: 92.4585 - val_smape: 72.9187\n",
      "Epoch 13/20\n",
      "327/327 [==============================] - 76s 232ms/step - loss: 0.9415 - accuracy: 0.4427 - mape: 94.1456 - smape: 73.6680 - val_loss: 0.7138 - val_accuracy: 0.4469 - val_mape: 94.3660 - val_smape: 73.3686\n",
      "Epoch 14/20\n",
      "327/327 [==============================] - 69s 211ms/step - loss: 0.9414 - accuracy: 0.4461 - mape: 94.4053 - smape: 73.8891 - val_loss: 0.7098 - val_accuracy: 0.4580 - val_mape: 95.1215 - val_smape: 73.6060\n",
      "Epoch 15/20\n",
      "327/327 [==============================] - 69s 210ms/step - loss: 0.9413 - accuracy: 0.4430 - mape: 94.7571 - smape: 74.1203 - val_loss: 0.7197 - val_accuracy: 0.4458 - val_mape: 93.2791 - val_smape: 73.1084\n",
      "Epoch 16/20\n",
      "327/327 [==============================] - 67s 206ms/step - loss: 0.9405 - accuracy: 0.4456 - mape: 94.8091 - smape: 74.0498 - val_loss: 0.7167 - val_accuracy: 0.4460 - val_mape: 93.7386 - val_smape: 73.2235\n",
      "Epoch 17/20\n",
      "327/327 [==============================] - 55s 170ms/step - loss: 0.9409 - accuracy: 0.4488 - mape: 93.5252 - smape: 73.3870 - val_loss: 0.7072 - val_accuracy: 0.4570 - val_mape: 96.1600 - val_smape: 73.7272\n",
      "Epoch 18/20\n",
      "327/327 [==============================] - 52s 160ms/step - loss: 0.9426 - accuracy: 0.4470 - mape: 94.4705 - smape: 73.7024 - val_loss: 0.7125 - val_accuracy: 0.4471 - val_mape: 94.6674 - val_smape: 73.4339\n",
      "Epoch 19/20\n",
      "327/327 [==============================] - 54s 165ms/step - loss: 0.9412 - accuracy: 0.4354 - mape: 94.5055 - smape: 74.0602 - val_loss: 0.7128 - val_accuracy: 0.4468 - val_mape: 94.5034 - val_smape: 73.4088\n",
      "Epoch 20/20\n",
      "327/327 [==============================] - 57s 173ms/step - loss: 0.9441 - accuracy: 0.4261 - mape: 94.4417 - smape: 73.8384 - val_loss: 0.7119 - val_accuracy: 0.4470 - val_mape: 94.5300 - val_smape: 73.4685\n",
      "\n",
      "Model Runtime: 23.32 Minutes\n"
     ]
    }
   ],
   "source": [
    "modelstart = time.time()\n",
    "history = modelCombined_Raw_GRU1_GRU2.fit(\n",
    "                    x=[X_train2D, xTrainLbk1, X_trainSized3D],\n",
    "                    y=y_train2D,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    class_weight = CLASS_WEIGHT,\n",
    "                    validation_data=([X_val2D, xValLbk1, X_valSized3D], y_val2D),\n",
    "                    validation_steps=validation_steps,\n",
    "                    steps_per_epoch=steps_per_epoch)\n",
    "modelCombined_Raw_GRU1_GRU2.save('COMBINED_RAW_GRU1_GRU2_01.h5')\n",
    "print(\"\\nModel Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f22eb",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "905bb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTestLbk1, yTestLbk1 = spliSequencesWithSamples(X_test, y_test, lookback1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8a9a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTestLbk2, yTestLbk2 = spliSequencesWithSamples(X_test, y_test, lookback2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57b3e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28993, 24, 6) (28993,)\n"
     ]
    }
   ],
   "source": [
    "X_testSized3D, y_testSized3D = reshape3DRowsFrom3DWindowed(xTestLbk2, yTestLbk2, xTestLbk1)\n",
    "print(X_testSized3D.shape, y_testSized3D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9b8b7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28993, 120, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTestLbk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab3d6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2D, y_test2D = reshape2DRowsFrom3DWindowed(X_test, y_test, xTestLbk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e3a1cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907/907 [==============================] - 48s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = modelCombined_Raw_GRU1_GRU2.predict([X_test2D, xTestLbk1, X_testSized3D])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d09881",
   "metadata": {},
   "source": [
    "### Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b2deab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit, profitPerTrade = calculateProfit(dfCleanRow, dX_test, yTestLbk1, pred, lookback=lookback1, specificity=.95, target='targetBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "081f92a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global profit :  9.150000000000006\n",
      "Average profit per trade :  0.0059146735617323885\n",
      "Global Number of trade made :  1547.0\n",
      "Average number of trade made per day :  1.2805849687855688\n"
     ]
    }
   ],
   "source": [
    "print('Global profit : ', profit)\n",
    "print('Average profit per trade : ', profitPerTrade)\n",
    "print('Global Number of trade made : ', profit / profitPerTrade)\n",
    "print('Average number of trade made per day : ', (profit / profitPerTrade) / len(pred) * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "211ce6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55661684],\n",
       "       [0.58072007],\n",
       "       [0.47798836],\n",
       "       ...,\n",
       "       [0.5036245 ],\n",
       "       [0.5373617 ],\n",
       "       [0.47648227]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3494a6e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4822f24",
   "metadata": {},
   "source": [
    "This model, based on Stacked GRU, seems to be the most promising so far. \n",
    "- It looks like using specificity 0.9 makes the model break even or close in term of profit. \n",
    "- Windows lookback timeframe is quite large 5 days (GRU are optimized)\n",
    "- Validation Loss decrease is not really progressive (Model unstable ?). Early stop cannot really be used. Metrics are a bit uneasy to read (class unbalanced ?)\n",
    "\n",
    "At this point we have a first basis, not great but could be promising with optimizations. In order to optimize we can answer this different questions :\n",
    "- Could it be helpfull to add some features ? (technical analysis, time feature)\n",
    "- Would it be possible, and usefull to adapt in order to have different time windows in \"parallel\" ? Not just 1 ?\n",
    "- Could it be interesting to use different loss or balanc the class ? In order to make model more \"stable\" in his progression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be13e67",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c6af1",
   "metadata": {},
   "source": [
    "1 - Add features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c154bd",
   "metadata": {},
   "source": [
    "-> Complete the dataset with calculated features\n",
    "- Add Time feature\n",
    "- Add Windows period tech indicators (Mostly short Windows as GRU has a large TimeFrame Window)\n",
    "\n",
    "-> Combine different time window in //\n",
    "- Multiple input usage. Idea behind is tech analysis uses multiple timefgrame analysis. Could be interesting to reproduce this in some way and not be \"fixed\" on a single specific lookback window timeframe.\n",
    "\n",
    "-> Add detail gain analysis\n",
    "Glabal result is important, but could be also nice to have a graphical view (monthly, daily) with standard deviation (sd -> risk)\n",
    "\n",
    "-> Renforce The results validations, calculations\n",
    "- Using Kfold validations (different set of test validations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19312202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
