{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b2e147",
   "metadata": {},
   "source": [
    "# Applications d'algo Deep Learning (NN) adaptés aux Time Series\n",
    "\n",
    "Il existe plusieurs types de modèles adaptés aux Time Series. Leur particularité est de ne pas utiliser simplement les données comme des évenements indépendants mais de conserver une \"mémoire\" des évenements précédents pour mieux analyser un instant T.\n",
    "\n",
    "Ceci est utile notamment pour trouver des pattern de tendance à terme. Voici les principaux modèles :\n",
    "- RNN  : Recurrent Neuronal Network\n",
    "- LSTM : Long Short-Term Memory\n",
    "- GRU  : Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a4b56",
   "metadata": {},
   "source": [
    "# Combinaison multi-input\n",
    "\n",
    "On a vu précédemment que les réseaux GRU ou LSTM donnaient les moins mauvais résultats (insufffisant). Les 2 utilisent des fenêtres d'inervalle de temps pour prédire un instant T à partir de plusieurs observations passés. Le GRU plutôt sur des grandes fenêtres, un peu plus courtes pour le LSTM.\n",
    "\n",
    "En analyse technique on va souvent utiliser plusieurs types de fenêtre d'interval (nb observations passées) simultanément. C'est ce qu'on va essayer de reproduire ici avec des réseaux combinants plusieurs input.\n",
    "\n",
    "Voici les 2 éléments qu'on va vouloir intégrer :\n",
    "- Information de base de l'observation (ellles sont noyés dans les observations de la fenêtre) donc on veut ici les répeter pour qu'elles soient \"conservées\"/non transformés.\n",
    "- Utilisation en parallèle de plusieurs layers (LSTM/GRU) en entrée qui vont pré-analyser les données avec fenêtrage mais sur des inetrvals de temps différents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d4063",
   "metadata": {},
   "source": [
    "#### First of all set randomeness in order to have comparable results between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34a3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592727c",
   "metadata": {},
   "source": [
    "## Constitution des datasets\n",
    "\n",
    "On va constituer 3 datasets différents avec une profondeur différente (nombre de variables) afin de pouvoir comparer notamment l'impact des indicateurs sur la qualité du résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bdb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f26a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d15cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8890cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Convolution1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.layers import LSTM, GRU, TimeDistributed, Conv1D, ConvLSTM2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from attention import Attention\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e2d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set randomeness to fix value to avoid different values on same model in different runs\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5578163",
   "metadata": {},
   "source": [
    "### Datasets : EURUSD H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47d232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = 'postgresql://postgres:Juw51000@localhost/tradingIA'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f676f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>mopen</th>\n",
       "      <th>mclose</th>\n",
       "      <th>mhigh</th>\n",
       "      <th>mlow</th>\n",
       "      <th>mvolume</th>\n",
       "      <th>mspread</th>\n",
       "      <th>ima</th>\n",
       "      <th>ima2</th>\n",
       "      <th>ima4</th>\n",
       "      <th>...</th>\n",
       "      <th>istos4</th>\n",
       "      <th>imom</th>\n",
       "      <th>imom2</th>\n",
       "      <th>imom4</th>\n",
       "      <th>rProfitBuy</th>\n",
       "      <th>rSwapBuy</th>\n",
       "      <th>rProfitBTrigger</th>\n",
       "      <th>rProfitSell</th>\n",
       "      <th>rSwapSell</th>\n",
       "      <th>rProfitSTrigger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946861200</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>194</td>\n",
       "      <td>50</td>\n",
       "      <td>1.008242</td>\n",
       "      <td>1.007963</td>\n",
       "      <td>1.006779</td>\n",
       "      <td>...</td>\n",
       "      <td>70.129870</td>\n",
       "      <td>100.536033</td>\n",
       "      <td>100.615935</td>\n",
       "      <td>100.565982</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-3.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>946864800</td>\n",
       "      <td>1.0129</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>1.0141</td>\n",
       "      <td>1.0120</td>\n",
       "      <td>113</td>\n",
       "      <td>50</td>\n",
       "      <td>1.008733</td>\n",
       "      <td>1.008175</td>\n",
       "      <td>1.006973</td>\n",
       "      <td>...</td>\n",
       "      <td>72.331461</td>\n",
       "      <td>100.675340</td>\n",
       "      <td>100.815515</td>\n",
       "      <td>100.495688</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>946868400</td>\n",
       "      <td>1.0140</td>\n",
       "      <td>1.0171</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0134</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>1.009517</td>\n",
       "      <td>1.008588</td>\n",
       "      <td>1.007215</td>\n",
       "      <td>...</td>\n",
       "      <td>76.041667</td>\n",
       "      <td>101.073239</td>\n",
       "      <td>101.002979</td>\n",
       "      <td>100.902778</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>946872000</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>1.0175</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>1.010350</td>\n",
       "      <td>1.008958</td>\n",
       "      <td>1.007462</td>\n",
       "      <td>...</td>\n",
       "      <td>78.688525</td>\n",
       "      <td>100.872410</td>\n",
       "      <td>100.962493</td>\n",
       "      <td>100.882411</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>946875600</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>1.0164</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>1.010975</td>\n",
       "      <td>1.009296</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>...</td>\n",
       "      <td>78.511530</td>\n",
       "      <td>100.703249</td>\n",
       "      <td>100.893123</td>\n",
       "      <td>100.813089</td>\n",
       "      <td>-2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SL</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       epoch   mopen  mclose   mhigh    mlow  mvolume  mspread       ima  \\\n",
       "0  946861200  1.0073  1.0128  1.0132  1.0073      194       50  1.008242   \n",
       "1  946864800  1.0129  1.0137  1.0141  1.0120      113       50  1.008733   \n",
       "2  946868400  1.0140  1.0171  1.0173  1.0134      149       50  1.009517   \n",
       "3  946872000  1.0170  1.0175  1.0190  1.0170      214       50  1.010350   \n",
       "4  946875600  1.0173  1.0167  1.0177  1.0164      162       50  1.010975   \n",
       "\n",
       "       ima2      ima4  ...     istos4        imom       imom2       imom4  \\\n",
       "0  1.007963  1.006779  ...  70.129870  100.536033  100.615935  100.565982   \n",
       "1  1.008175  1.006973  ...  72.331461  100.675340  100.815515  100.495688   \n",
       "2  1.008588  1.007215  ...  76.041667  101.073239  101.002979  100.902778   \n",
       "3  1.008958  1.007462  ...  78.688525  100.872410  100.962493  100.882411   \n",
       "4  1.009296  1.007677  ...  78.511530  100.703249  100.893123  100.813089   \n",
       "\n",
       "   rProfitBuy  rSwapBuy  rProfitBTrigger  rProfitSell  rSwapSell  \\\n",
       "0        3.64       0.0               TO        -3.07        0.0   \n",
       "1        2.56       0.0               TO        -3.15        0.0   \n",
       "2       -0.10       0.0               TO        -0.88        0.0   \n",
       "3       -2.36       0.0               TO         1.38        0.0   \n",
       "4       -2.95       0.0               SL         5.74        0.0   \n",
       "\n",
       "   rProfitSTrigger  \n",
       "0               SL  \n",
       "1               SL  \n",
       "2               TO  \n",
       "3               TO  \n",
       "4               TP  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"select * from fex_eurusd_h1\", conn);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e0718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['targetBuy'] = df['rProfitBuy'] + df['rSwapBuy']\n",
    "df['targetSell'] = df['rProfitSell'] + df['rSwapSell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06a3339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145559, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNotNa = df[df['rProfitBTrigger'].notna()]\n",
    "dfCleanRow = dfNotNa[dfNotNa['epoch'] < 1690484400]\n",
    "dfClean = dfCleanRow.drop(['rProfitBuy', 'rSwapBuy', 'rProfitSell', 'rSwapSell', 'rProfitSTrigger', 'rProfitBTrigger'], axis=1)\n",
    "dfClean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6890a",
   "metadata": {},
   "source": [
    "### Transposition en problème de classification binaire\n",
    "\n",
    "On peut simplifier la question de base qui est de savoir quel est le moment du profit (Buy/Sell) en question binaire, à savoir est-ce que le trade à un instant T (Buy et Sell) entrainera une perte (0) ou un gain (1) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e27e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin = dfClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03ecad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145559, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanBin['targetProfitBuy'] = dfCleanBin['targetBuy'].apply(lambda x: 1 if x > 0 else 0)\n",
    "dfCleanBin['targetProfitSell'] = dfCleanBin['targetSell'].apply(lambda x: 1 if x > 0 else 0)\n",
    "dfCleanBin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baa6c763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33065.310000000005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetBuy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285bc1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37148510226093884"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetProfitBuy']) / dfCleanBin.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5425ca90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32935.02000000026"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetSell'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae040253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37439801042876086"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dfCleanBin['targetProfitSell']) / dfCleanBin.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06db9b96",
   "metadata": {},
   "source": [
    "Qu'il s'agisse des Profits Buy ou Sell on est à environ 37% de target Profit pour 63% de perte. Les classes sont donc plutôt équilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea402816",
   "metadata": {},
   "source": [
    "### Glissement des valeurs Target (prévision)\n",
    "\n",
    "Pour la prévision les valeurs à prédire (profit du trade) sont les valeurs qui concernent la periode à venir du trade (T+1) en fonction des features observées sur la periode actuelle (T). On doit donc glisser les valeurs de Target de T+1 vers T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2b9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin['targetProfitBuy'] = dfCleanBin['targetProfitBuy'].shift(-1)\n",
    "dfCleanBin['targetProfitSell'] = dfCleanBin['targetProfitSell'].shift(-1)\n",
    "dfCleanBin['targetSell'] = dfCleanBin['targetSell'].shift(-1)\n",
    "dfCleanBin['targetBuy'] = dfCleanBin['targetBuy'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82ca4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin = dfCleanBin[dfCleanBin['targetProfitSell'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12957051",
   "metadata": {},
   "source": [
    "### Transformation du prix d'ouverture\n",
    "\n",
    "Le prix d'ouverture T est finalement le prix de clôture T-1 (avec possible légère correction), il n'est donc pas primordial.\n",
    "On aimerait mieux peut-être visualiser facilement le sens de tendance de la periode (Prix cloture - Prix ouverture) plus révélateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f00fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin['evol'] = dfCleanBin['mclose'] - dfCleanBin['mopen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6d9f9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    145558.000000\n",
       "mean          0.000004\n",
       "std           0.001462\n",
       "min          -0.024800\n",
       "25%          -0.000600\n",
       "50%           0.000000\n",
       "75%           0.000600\n",
       "max           0.030200\n",
       "Name: evol, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanBin['evol'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aac8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanBin.set_index('epoch', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dbd21",
   "metadata": {},
   "source": [
    "#### Dataset basis\n",
    "Ce dataset ne va comporfter que les données brutes (en plus des target) sans aucun indicateur technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d0eaa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBasisB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy']]\n",
    "dfBasisS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb0548",
   "metadata": {},
   "source": [
    "#### Dataset intermediate low\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi que la version des indicateurs sur la plus courte periode de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "399d5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntLowB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd', 'istos', 'imom']]\n",
    "dfIntLowS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd', 'istos', 'imom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb372ccd",
   "metadata": {},
   "source": [
    "#### Dataset intermediate Medium\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi que la version des indicateurs sur la periode de calcul intermediaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af77f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntMedB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima2', 'iatr2', 'irsi2', 'imacd2', 'istos2', 'imom2']]\n",
    "dfIntMedS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima2', 'iatr2', 'irsi2', 'imacd2', 'istos2', 'imom2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca9bb5",
   "metadata": {},
   "source": [
    "#### Dataset intermediate High\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi que la version des indicateurs sur la plus longue periode de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49f530c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntHigB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima4', 'iatr4', 'irsi4', 'imacd4', 'istos4', 'imom4']]\n",
    "dfIntHigS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima4', 'iatr4', 'irsi4', 'imacd4', 'istos4', 'imom4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb0eb3",
   "metadata": {},
   "source": [
    "#### Dataset Complet\n",
    "Ce dataset, va comporfter les données brutes (en plus des target) ainsi tous les indicateurs sur toutes les periodes de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9dfd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFullB = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitBuy', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd','ima2', 'iatr2', 'irsi2', 'imacd2','ima4', 'iatr4', 'irsi4', 'imacd4',\n",
    "                   'istos', 'istos2', 'istos4', 'imom', 'imom2', 'imom4']]\n",
    "dfFullS = dfCleanBin[['mopen', 'mclose', 'mhigh', 'mlow', 'mvolume', 'mspread', 'targetProfitSell', \n",
    "                   'ima', 'iatr', 'irsi', 'imacd','ima2', 'iatr2', 'irsi2', 'imacd2','ima4', 'iatr4', 'irsi4', 'imacd4',\n",
    "                   'istos', 'istos2', 'istos4', 'imom', 'imom2', 'imom4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ecc91",
   "metadata": {},
   "source": [
    "## Applications des Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bfb79",
   "metadata": {},
   "source": [
    "#### Utilisation du modele de base : dfBasisB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ab1dc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145558, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBasisB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487706f3",
   "metadata": {},
   "source": [
    "#### Definition des datsests de Features / Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69cdbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfBasisB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a488a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTarget = df['targetProfitBuy']\n",
    "dfFeatures = df.drop(columns=['targetProfitBuy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d8c5f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ead39ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testYears = [2016, 2018, 2022]\n",
    "validYears = [2017, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "750c84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstEpochs = dfFeatures.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cdcc61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEpochs = list(filter(lambda s: isDateTimeinYears(datetime.utcfromtimestamp(s), testYears), lstEpochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbc87050",
   "metadata": {},
   "outputs": [],
   "source": [
    "validEpochs = list(filter(lambda s: isDateTimeinYears(datetime.utcfromtimestamp(s), validYears), lstEpochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8de785ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEpochs = list(filter(lambda s: not isDateTimeinYears(datetime.utcfromtimestamp(s), testYears) \n",
    "                           and not isDateTimeinYears(datetime.utcfromtimestamp(s), validYears), lstEpochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78856065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full epoch list :  145558\n",
      "full train list :  114624\n",
      "full valid list :  12368\n",
      "full test list :  18566\n"
     ]
    }
   ],
   "source": [
    "print('full epoch list : ', len(lstEpochs))\n",
    "print('full train list : ', len(trainEpochs))\n",
    "print('full valid list : ', len(validEpochs))\n",
    "print('full test list : ', len(testEpochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53335a",
   "metadata": {},
   "source": [
    "#### Spécificité LSTM / GRU : Separation des données en sous-ensembles\n",
    "\n",
    "Les LSTM travaillent par lots (sous-ensembles) qui déterminent pour une instance donné quelles sont les instances précédentes qui doivent lui être associées.\n",
    "\n",
    "Dans le contexte du trading on va donner pour chaque extrait de données à un instant T un nombre n (paramètre) d'extraits qui le précédent directement dans le temps [T-1 .... T-n], et qui vont être utilisés par LSTM pour comprendre la donnée à l'instant T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3231181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliSequencesWithSamples(xdata, ydata, lookback):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(xdata)):\n",
    "        if (i>=lookback-1): # Rows with not enough prev values cannot be taken\n",
    "            # gather input and output parts of the pattern\n",
    "            seq_x, seq_y = xdata[i+1-lookback:i+1, :], ydata[i]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)  \n",
    "    return(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe4c58",
   "metadata": {},
   "source": [
    "## Layers definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68842cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeWindowedGRU(nbFeatures, lookback):\n",
    "    inputWindow = Input(shape=(lookback, nbFeatures))\n",
    "    # GRU input : [timesteps, features] \n",
    "    mem1 = GRU(32, return_sequences = True, activation='tanh', kernel_initializer='TruncatedNormal')(inputWindow)    \n",
    "    mem2 = GRU(8,  return_sequences = False, activation='tanh', kernel_initializer='TruncatedNormal')(mem1)\n",
    "    return Model(inputs=inputWindow, outputs=mem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36cc629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeWindowedLSTM(nbFeatures, lookback):\n",
    "    inputWindow = Input(shape=(lookback, nbFeatures))\n",
    "    # LSTM input : [timesteps, features] \n",
    "    mem1 = LSTM(32, return_sequences = False, activation='tanh')(inputWindow)   \n",
    "    #mem2 = LSTM(8,  return_sequences = False, activation='tanh')(mem1)\n",
    "    return Model(inputs=inputWindow, outputs=mem1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ace13a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTMWithAttention(nbFeatures, lookback):\n",
    "    inputWindow = Input(shape=(lookback, nbFeatures))\n",
    "    # LSTM input : [timesteps, features] \n",
    "    mem1 = LSTM(32, return_sequences = True, activation='tanh')(inputWindow)   \n",
    "    att =  Attention(64)(mem1)\n",
    "    dense = Dense(32)(att)\n",
    "    return Model(inputs=inputWindow, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e81f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRawDataBranch(nbFeatures):\n",
    "    inputRaw = Input(shape=(nbFeatures))\n",
    "    return Model(inputs=inputRaw, outputs=inputRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "454d8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBranche(nbFeatures, lookback, typeLayer):\n",
    "    match typeLayer:\n",
    "        case \"RAW\":\n",
    "            return createRawDataBranch(nbFeatures)\n",
    "        case \"GRU\":\n",
    "            return createTimeWindowedGRU(nbFeatures, lookback)\n",
    "        case \"LSTM\":\n",
    "            return createTimeWindowedLSTM(nbFeatures, lookback)\n",
    "        case \"LSTMAT\":\n",
    "            return createLSTMWithAttention(nbFeatures, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee72153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineBranches(lstBranches):\n",
    "    lstOutput = [branche.output for branche in lstBranches]\n",
    "    return layers.concatenate(lstOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "031a3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelInputs(lstBranches):\n",
    "    return [branche.input for branche in lstBranches]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536c750",
   "metadata": {},
   "source": [
    "#### Create NN model from a dataset with the associated layers (Raw / LSTM / GRU) with specified window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7efd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMultiWindowedInput(nbFeatures, nbWindows, lstLookback, lstLayers):\n",
    "    lstBranches = []\n",
    "    for i in range(nbWindows):\n",
    "        lookback = lstLookback[i]\n",
    "        branche = createBranche(nbFeatures, lookback, lstLayers[i])\n",
    "        lstBranches.append(branche)\n",
    "    combined = combineBranches(lstBranches)\n",
    "    # Fully connected layers, with 1 final output for binary classification\n",
    "    #d0 = BatchNormalization()(combined)\n",
    "    d1 = Dense(16, name='Dense_1', activation='relu')(combined)\n",
    "    d2 = Dense(8, name='Dense_2', activation='relu')(d1)\n",
    "    d3 = Dense(1, name='Dense_3', activation='sigmoid')(d2)\n",
    "    lstInputs = createModelInputs(lstBranches)\n",
    "    model = Model(inputs=lstInputs, outputs=d3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00188bb",
   "metadata": {},
   "source": [
    "#### Set model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16e220ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstLookback = [24]\n",
    "lstLayers   = ['LSTMAT']\n",
    "nbInput = len(lstLookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c1776bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b6dd395",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "coucou",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoucou\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: coucou"
     ]
    }
   ],
   "source": [
    "raise Exception('coucou')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb410a02",
   "metadata": {},
   "source": [
    "#### Format dataset and Time Windows for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5b7a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliSequencesWithSamples(xdata, ydata, lookback):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(xdata)):\n",
    "        if (i>=lookback-1): # Rows with not enough prev values cannot be taken\n",
    "            # gather input and output parts of the pattern\n",
    "            seq_x, seq_y = xdata[i+1-lookback:i+1, :], ydata[i]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)  \n",
    "    return(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61b5cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataWindowed(xData2D, lookback, maxLookback):\n",
    "    X = list()\n",
    "    if lookback == 0:\n",
    "        return xData2D[maxLookback-1:,:]\n",
    "    else:\n",
    "        for i in range(len(xData2D)):\n",
    "            if (i>=maxLookback-1): # Rows with not enough prev values cannot be taken\n",
    "                seq_x = xData2D[i+1-lookback:i+1, :]\n",
    "                positions = np.arange(0, lookback).reshape(lookback, 1)\n",
    "                seq_x = np.hstack((seq_x, positions))\n",
    "                X.append(seq_x) \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbc2815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Windowed dataset (xData in 3D) and label (yData1D) sized. Number of rows has to match with the maximum Windowed dataset\n",
    "def formatWindowedData(lstLookback, xData2D, yData1D):\n",
    "    maxLookback = max(lstLookback)\n",
    "    lstxData3D = [getDataWindowed(xData2D, lookback, maxLookback) for lookback in lstLookback]\n",
    "    yDataReshape1D = yData1D[maxLookback-1:]\n",
    "    return lstxData3D, yDataReshape1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8281ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataWindowed, y_dataWindowed = formatWindowedData(lstLookback, dfFeatures.values, dfTarget.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4b0d6",
   "metadata": {},
   "source": [
    "#### Use time periods to split dataset \n",
    "\n",
    "- 3 distincts periods in last 8 years will be used for testing, in order to make results more robusts\n",
    "- Validation set will produced wityh 2 differents years in the last 8 years as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c906137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testYears = [2016, 2018, 2022]\n",
    "validYears = [2017, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1aa4eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDateTimeinYears(date, lstYears):\n",
    "    return date.year in lstYears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "109832e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust list of epochs. remove first rows as not used in Window Timeframe due to lockback depth reuqired.\n",
    "lstEpochs = dfFeatures.index.to_list()[max(lstLookback)-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a744a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEpochs = list(filter(lambda s: isDateTimeinYears(datetime.utcfromtimestamp(s), testYears), lstEpochs))\n",
    "validEpochs = list(filter(lambda s: isDateTimeinYears(datetime.utcfromtimestamp(s), validYears), lstEpochs))\n",
    "trainEpochs = list(filter(lambda s: not isDateTimeinYears(datetime.utcfromtimestamp(s), testYears) \n",
    "                           and not isDateTimeinYears(datetime.utcfromtimestamp(s), validYears), lstEpochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f838212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full epoch list :  145535\n",
      "full train list :  114601\n",
      "full valid list :  12368\n",
      "full test list :  18566\n"
     ]
    }
   ],
   "source": [
    "print('full epoch list : ', len(lstEpochs))\n",
    "print('full train list : ', len(trainEpochs))\n",
    "print('full valid list : ', len(validEpochs))\n",
    "print('full test list : ', len(testEpochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f94d4a",
   "metadata": {},
   "source": [
    "#### Split des données (train / valid / test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2902c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Row index for each dataset\n",
    "indexTrain = [trainEpochs.index(epoch) for epoch in trainEpochs]\n",
    "indexVal   = [validEpochs.index(epoch) for epoch in validEpochs]\n",
    "indexTest  = [testEpochs.index(epoch) for epoch in testEpochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b59ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = [x_dataW[indexTrain] for x_dataW in x_dataWindowed]\n",
    "xVal   = [x_dataW[indexVal] for x_dataW in x_dataWindowed]\n",
    "xTest  = [x_dataW[indexTest] for x_dataW in x_dataWindowed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e38c2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = y_dataWindowed[indexTrain] \n",
    "yVal   = y_dataWindowed[indexVal]\n",
    "yTest  = y_dataWindowed[indexTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff3e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84893e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188179ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9bb38188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114601, 24, 7)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f9d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bcf19fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[[2, 23, 567], [3, 43, 390], [4, 24, 678]], [[3, 24, 564], [4, 47, 432], [6, 34, 431]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0727ad2",
   "metadata": {},
   "source": [
    "#### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3002fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize3D(data3D):\n",
    "    data2D = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainNorm = [normalize3D(x) for x in xTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36707f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "26611067",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d267e2a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxTrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TRADING_IA_MACHINE_LEARNING\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TRADING_IA_MACHINE_LEARNING\\lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TRADING_IA_MACHINE_LEARNING\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TRADING_IA_MACHINE_LEARNING\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m    860\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 861\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TRADING_IA_MACHINE_LEARNING\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TRADING_IA_MACHINE_LEARNING\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 4. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "X_train = scaler.fit_transform(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958912f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad251784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "10a6d38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.00730e+00, 1.01280e+00, 1.01320e+00, ..., 1.94000e+02,\n",
       "         5.00000e+01, 0.00000e+00],\n",
       "        [1.01290e+00, 1.01370e+00, 1.01410e+00, ..., 1.13000e+02,\n",
       "         5.00000e+01, 1.00000e+00],\n",
       "        [1.01400e+00, 1.01710e+00, 1.01730e+00, ..., 1.49000e+02,\n",
       "         5.00000e+01, 2.00000e+00],\n",
       "        ...,\n",
       "        [1.02730e+00, 1.02560e+00, 1.02760e+00, ..., 1.36000e+02,\n",
       "         5.00000e+01, 2.10000e+01],\n",
       "        [1.02570e+00, 1.02430e+00, 1.02680e+00, ..., 1.25000e+02,\n",
       "         5.00000e+01, 2.20000e+01],\n",
       "        [1.02430e+00, 1.02460e+00, 1.02470e+00, ..., 6.90000e+01,\n",
       "         5.00000e+01, 2.30000e+01]],\n",
       "\n",
       "       [[1.01290e+00, 1.01370e+00, 1.01410e+00, ..., 1.13000e+02,\n",
       "         5.00000e+01, 0.00000e+00],\n",
       "        [1.01400e+00, 1.01710e+00, 1.01730e+00, ..., 1.49000e+02,\n",
       "         5.00000e+01, 1.00000e+00],\n",
       "        [1.01700e+00, 1.01750e+00, 1.01900e+00, ..., 2.14000e+02,\n",
       "         5.00000e+01, 2.00000e+00],\n",
       "        ...,\n",
       "        [1.02570e+00, 1.02430e+00, 1.02680e+00, ..., 1.25000e+02,\n",
       "         5.00000e+01, 2.10000e+01],\n",
       "        [1.02430e+00, 1.02460e+00, 1.02470e+00, ..., 6.90000e+01,\n",
       "         5.00000e+01, 2.20000e+01],\n",
       "        [1.02430e+00, 1.02370e+00, 1.02510e+00, ..., 1.01000e+02,\n",
       "         5.00000e+01, 2.30000e+01]],\n",
       "\n",
       "       [[1.01400e+00, 1.01710e+00, 1.01730e+00, ..., 1.49000e+02,\n",
       "         5.00000e+01, 0.00000e+00],\n",
       "        [1.01700e+00, 1.01750e+00, 1.01900e+00, ..., 2.14000e+02,\n",
       "         5.00000e+01, 1.00000e+00],\n",
       "        [1.01730e+00, 1.01670e+00, 1.01770e+00, ..., 1.62000e+02,\n",
       "         5.00000e+01, 2.00000e+00],\n",
       "        ...,\n",
       "        [1.02430e+00, 1.02460e+00, 1.02470e+00, ..., 6.90000e+01,\n",
       "         5.00000e+01, 2.10000e+01],\n",
       "        [1.02430e+00, 1.02370e+00, 1.02510e+00, ..., 1.01000e+02,\n",
       "         5.00000e+01, 2.20000e+01],\n",
       "        [1.02370e+00, 1.02620e+00, 1.02660e+00, ..., 2.84000e+02,\n",
       "         5.00000e+01, 2.30000e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.10680e+00, 1.10650e+00, 1.10730e+00, ..., 3.97600e+03,\n",
       "         6.00000e+00, 0.00000e+00],\n",
       "        [1.10649e+00, 1.10633e+00, 1.10712e+00, ..., 4.30600e+03,\n",
       "         6.00000e+00, 1.00000e+00],\n",
       "        [1.10633e+00, 1.10765e+00, 1.10794e+00, ..., 3.22300e+03,\n",
       "         6.00000e+00, 2.00000e+00],\n",
       "        ...,\n",
       "        [1.11393e+00, 1.11370e+00, 1.11494e+00, ..., 2.37200e+03,\n",
       "         6.00000e+00, 2.10000e+01],\n",
       "        [1.11370e+00, 1.11383e+00, 1.11409e+00, ..., 2.52600e+03,\n",
       "         6.00000e+00, 2.20000e+01],\n",
       "        [1.11382e+00, 1.10591e+00, 1.11389e+00, ..., 9.04400e+03,\n",
       "         6.00000e+00, 2.30000e+01]],\n",
       "\n",
       "       [[1.10649e+00, 1.10633e+00, 1.10712e+00, ..., 4.30600e+03,\n",
       "         6.00000e+00, 0.00000e+00],\n",
       "        [1.10633e+00, 1.10765e+00, 1.10794e+00, ..., 3.22300e+03,\n",
       "         6.00000e+00, 1.00000e+00],\n",
       "        [1.10765e+00, 1.10715e+00, 1.10820e+00, ..., 1.79200e+03,\n",
       "         6.00000e+00, 2.00000e+00],\n",
       "        ...,\n",
       "        [1.11370e+00, 1.11383e+00, 1.11409e+00, ..., 2.52600e+03,\n",
       "         6.00000e+00, 2.10000e+01],\n",
       "        [1.11382e+00, 1.10591e+00, 1.11389e+00, ..., 9.04400e+03,\n",
       "         6.00000e+00, 2.20000e+01],\n",
       "        [1.10588e+00, 1.10077e+00, 1.10651e+00, ..., 9.32700e+03,\n",
       "         6.00000e+00, 2.30000e+01]],\n",
       "\n",
       "       [[1.10633e+00, 1.10765e+00, 1.10794e+00, ..., 3.22300e+03,\n",
       "         6.00000e+00, 0.00000e+00],\n",
       "        [1.10765e+00, 1.10715e+00, 1.10820e+00, ..., 1.79200e+03,\n",
       "         6.00000e+00, 1.00000e+00],\n",
       "        [1.10715e+00, 1.10571e+00, 1.10716e+00, ..., 1.82500e+03,\n",
       "         6.00000e+00, 2.00000e+00],\n",
       "        ...,\n",
       "        [1.11382e+00, 1.10591e+00, 1.11389e+00, ..., 9.04400e+03,\n",
       "         6.00000e+00, 2.10000e+01],\n",
       "        [1.10588e+00, 1.10077e+00, 1.10651e+00, ..., 9.32700e+03,\n",
       "         6.00000e+00, 2.20000e+01],\n",
       "        [1.10077e+00, 1.09916e+00, 1.10103e+00, ..., 6.97200e+03,\n",
       "         6.00000e+00, 2.30000e+01]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dataWindowed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af55cd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mopen</th>\n",
       "      <th>mclose</th>\n",
       "      <th>mhigh</th>\n",
       "      <th>mlow</th>\n",
       "      <th>mvolume</th>\n",
       "      <th>mspread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946861200</th>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>194</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946864800</th>\n",
       "      <td>1.0129</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>1.0141</td>\n",
       "      <td>1.0120</td>\n",
       "      <td>113</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946868400</th>\n",
       "      <td>1.0140</td>\n",
       "      <td>1.0171</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0134</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946872000</th>\n",
       "      <td>1.0170</td>\n",
       "      <td>1.0175</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946875600</th>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>1.0164</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mopen  mclose   mhigh    mlow  mvolume  mspread\n",
       "epoch                                                      \n",
       "946861200  1.0073  1.0128  1.0132  1.0073      194       50\n",
       "946864800  1.0129  1.0137  1.0141  1.0120      113       50\n",
       "946868400  1.0140  1.0171  1.0173  1.0134      149       50\n",
       "946872000  1.0170  1.0175  1.0190  1.0170      214       50\n",
       "946875600  1.0173  1.0167  1.0177  1.0164      162       50"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xFeaturesWindowed, dfTargetT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065b27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267d7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16269d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d49565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41fbf994",
   "metadata": {},
   "source": [
    "Split into (Train + Valid) / Test datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeaturesT, dX_test, dfTargetT, dy_test = getTrainTestDatasets2(dfFeatures, dfTarget, .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a21933",
   "metadata": {},
   "source": [
    "Split into Train / Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aed2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_train, dX_val, dy_train, dy_val = getTrainTestDatasets2(dfFeaturesT, dfTargetT, .9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd430d9b",
   "metadata": {},
   "source": [
    "#### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c513ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(dX_train)\n",
    "X_test = scaler.transform(dX_test)\n",
    "X_val = scaler.transform(dX_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60269a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dy_train.to_numpy()\n",
    "y_test = dy_test.to_numpy()\n",
    "y_val = dy_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22067119",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9fe271",
   "metadata": {},
   "source": [
    "#### Spécificité LSTM / GRU : Separation des données en sous-ensembles\n",
    "\n",
    "Les LSTM travaillent par lots (sous-ensembles) qui déterminent pour une instance donné quelles sont les instances précédentes qui doivent lui être associées.\n",
    "\n",
    "Dans le contexte du trading on va donner pour chaque extrait de données à un instant T un nombre n (paramètre) d'extraits qui le précédent directement dans le temps [T-1 .... T-n], et qui vont être utilisés par LSTM pour comprendre la donnée à l'instant T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74471bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliSequencesWithSamples(xdata, ydata, lookback):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(xdata)):\n",
    "        if (i>=lookback-1): # Rows with not enough prev values cannot be taken\n",
    "            # gather input and output parts of the pattern\n",
    "            seq_x, seq_y = xdata[i+1-lookback:i+1, :], ydata[i]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)  \n",
    "    return(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae8f7b",
   "metadata": {},
   "source": [
    "## Calcul des scores et gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa490266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRandomProfit(dfCleanRow, target='targetBuy'):\n",
    "    profit = dfCleanRow[target].sum()\n",
    "    profitPerTrade = profit / len(dfCleanRow)\n",
    "    return profit, profitPerTrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfebcc",
   "metadata": {},
   "source": [
    "### Calcul des scores et gains (model 100 % aléatoire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "profitRandom, profitPerTradeRandom = calculateRandomProfit(dfCleanRow, target='targetBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profitRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffe62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "profitPerTradeRandom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf242d1",
   "metadata": {},
   "source": [
    "## LSTM SINGLE LAYER\n",
    "\n",
    "NN will have just 1 LSTM Layer before the Fully Connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e34a2",
   "metadata": {},
   "source": [
    "Custom Metric functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e81e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeWindowedGRU(nbFeatures, lookback):\n",
    "    inputWindow = Input(shape=(lookback, nbFeatures))\n",
    "    # GRU input : [timesteps, features] \n",
    "    mem1 = GRU(32, return_sequences = True, activation='tanh', kernel_initializer='TruncatedNormal')(inputWindow)    \n",
    "    mem2 = GRU(8,  return_sequences = False, activation='tanh', kernel_initializer='TruncatedNormal')(mem1)\n",
    "    return Model(inputs=inputWindow, outputs=mem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeWindowedLSTM(nbFeatures, lookback):\n",
    "    inputWindow = Input(shape=(lookback, nbFeatures))\n",
    "    # LSTM input : [timesteps, features] \n",
    "    mem1 = LSTM(32, return_sequences = False, activation='tanh')(inputWindow)   \n",
    "    #mem2 = LSTM(8,  return_sequences = False, activation='tanh')(mem1)\n",
    "    return Model(inputs=inputWindow, outputs=mem1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa24121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTMWithAttention(nbFeatures, lookback):\n",
    "    inputWindow = Input(shape=(lookback, nbFeatures))\n",
    "    # LSTM input : [timesteps, features] \n",
    "    mem1 = LSTM(32, return_sequences = True, activation='tanh')(inputWindow)   \n",
    "    att =  Attention(64)(mem1)\n",
    "    dense = Dense(32)(att)\n",
    "    return Model(inputs=inputWindow, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRawDataBranch(nbFeatures):\n",
    "    inputRaw = Input(shape=(nbFeatures))\n",
    "    return Model(inputs=inputRaw, outputs=inputRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e820e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBranche(nbFeatures, lookback, typeLayer):\n",
    "    match typeLayer:\n",
    "        case \"RAW\":\n",
    "            return createRawDataBranch(nbFeatures)\n",
    "        case \"GRU\":\n",
    "            return createTimeWindowedGRU(nbFeatures, lookback)\n",
    "        case \"LSTM\":\n",
    "            return createTimeWindowedLSTM(nbFeatures, lookback)\n",
    "        case \"LSTMAT\":\n",
    "            return createLSTMWithAttention(nbFeatures, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08cad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineBranches(lstBranches):\n",
    "    lstOutput = [branche.output for branche in lstBranches]\n",
    "    return layers.concatenate(lstOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5513bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelInputs(lstBranches):\n",
    "    return [branche.input for branche in lstBranches]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a8fe3",
   "metadata": {},
   "source": [
    "#### Create NN model from a dataset with the associated layers (Raw / LSTM / GRU) with specified window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25988e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMultiWindowedInput(nbFeatures, nbWindows, lstLookback, lstLayers):\n",
    "    lstBranches = []\n",
    "    for i in range(nbWindows):\n",
    "        lookback = lstLookback[i]\n",
    "        branche = createBranche(nbFeatures, lookback, lstLayers[i])\n",
    "        lstBranches.append(branche)\n",
    "    combined = combineBranches(lstBranches)\n",
    "    # Fully connected layers, with 1 final output for binary classification\n",
    "    #d0 = BatchNormalization()(combined)\n",
    "    d1 = Dense(16, name='Dense_1', activation='relu')(combined)\n",
    "    d2 = Dense(8, name='Dense_2', activation='relu')(d1)\n",
    "    d3 = Dense(1, name='Dense_3', activation='sigmoid')(d2)\n",
    "    lstInputs = createModelInputs(lstBranches)\n",
    "    model = Model(inputs=lstInputs, outputs=d3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstLookback = [24]\n",
    "lstLayers   = ['LSTMAT']\n",
    "nbInput = len(lstLookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95482893",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a537b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldyn = buildMultiWindowedInput(X_train.shape[1], nbInput, lstLookback, lstLayers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6baa48d",
   "metadata": {},
   "source": [
    "#### Format dataset and Time Windows for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliSequencesWithSamples(xdata, ydata, lookback):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(xdata)):\n",
    "        if (i>=lookback-1): # Rows with not enough prev values cannot be taken\n",
    "            # gather input and output parts of the pattern\n",
    "            seq_x, seq_y = xdata[i+1-lookback:i+1, :], ydata[i]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)  \n",
    "    return(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataWindowed(xData2D, lookback, maxLookback):\n",
    "    X = list()\n",
    "    if lookback == 0:\n",
    "        return xData2D[maxLookback-1:,:]\n",
    "    else:\n",
    "        for i in range(len(xData2D)):\n",
    "            if (i>=maxLookback-1): # Rows with not enough prev values cannot be taken\n",
    "                seq_x = xData2D[i+1-lookback:i+1, :]\n",
    "                X.append(seq_x) \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45927d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Windowed dataset (xData in 3D) and label (yData1D) sized. Number of rows has to match with the maximum Windowed dataset\n",
    "def formatWindowedData(lstLookback, xData2D, yData1D):\n",
    "    maxLookback = max(lstLookback)\n",
    "    lstxData3D = [getDataWindowed(xData2D, lookback, maxLookback) for lookback in lstLookback]\n",
    "    yDataReshape1D = yData1D[maxLookback-1:]\n",
    "    return lstxData3D, yDataReshape1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldyn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathModelWeights = 'weights/NN_LSTM_SINGLE_ATTENTION_07_WEIGHTS.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe994bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST : Reload always the same init weights in order to compare results easily\n",
    "if os.path.isfile(pathModelWeights):\n",
    "    modeldyn.load_weights(pathModelWeights)\n",
    "    print('Model : Reload Weights Done')\n",
    "else:\n",
    "    modeldyn.save_weights(pathModelWeights)\n",
    "    print('Model : Save Weights Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52662999",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstxTrainWindowed3D, yTrained1D = formatWindowedData(lstLookback, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19adcf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstxValWindowed3D, yVal1D = formatWindowedData(lstLookback, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58cae4",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0316110",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 4\n",
    "EPOCHS = 10\n",
    "LOOP = 10\n",
    "BATCH_SIZE = 32 # Default used my model.fit is 32\n",
    "steps_per_epoch = yTrained1D.shape[0] * LOOP / EPOCHS // BATCH_SIZE    # Split all data by Epochs ()\n",
    "validation_steps = yVal1D.shape[0] // BATCH_SIZE                       # Take all validation data for validation on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee229345",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_WEIGHT = {0: .37, 1 : .63} # Use to counter unbalnced class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience = PATIENCE, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelstart = time.time()\n",
    "history = modeldyn.fit(\n",
    "                    x=lstxTrainWindowed3D,\n",
    "                    y=yTrained1D,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    #class_weight = CLASS_WEIGHT,\n",
    "                    validation_data=(lstxValWindowed3D, yVal1D),\n",
    "                    validation_steps=validation_steps,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks=early_stopping)\n",
    "# modeldyn.save('NN_LSTM_SINGLE_01.h5')\n",
    "print(\"\\nModel Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f22eb",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstxTestWindowed3D, yTest1D = formatWindowedData(lstLookback, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = modeldyn.predict(lstxTestWindowed3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c28dc",
   "metadata": {},
   "source": [
    "### Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290301cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProfitQ(dfCleanRow, dX_test, yTestLbk, pred, lookback=100, quantile=.8, target='targetBuy'):\n",
    "    dfPred = pd.DataFrame(pred, columns = ['proba'])\n",
    "    seuil = dfPred['proba'].quantile(quantile)\n",
    "    #Get rows index with positive proba (proba > seuil)\n",
    "    xRows = dfPred[dfPred['proba']>seuil].index.to_numpy()\n",
    "    #Get matching index (epoch timestamp) from dX_test => Periods with proba > seuil\n",
    "    xEpochs = dX_test.iloc[lookback-1:,:].iloc[xRows].index.to_numpy()\n",
    "    dfCleanEpochIdx = dfCleanRow.set_index('epoch')\n",
    "    profit = dfCleanEpochIdx.loc[xEpochs][target].sum()\n",
    "    profitPerTrade = profit / len(xRows)\n",
    "    return profit, profitPerTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProfitS(dfCleanRow, dX_test, yTestLbk, pred, lookback=100, specificity=.8, target='targetBuy'):\n",
    "    [fpr, tpr, thr] = roc_curve(yTestLbk, pred, pos_label=1)\n",
    "    idx = np.max(np.where((1-fpr) > specificity)) \n",
    "    seuil = thr[idx]  \n",
    "    dfPred = pd.DataFrame(pred, columns = ['proba'])\n",
    "    #Get rows index with positive proba (proba > seuil)\n",
    "    xRows = dfPred[dfPred['proba']>seuil].index.to_numpy()\n",
    "    #Get matching index (epoch timestamp) from dX_test => Periods with proba > seuil\n",
    "    xEpochs = dX_test.iloc[lookback-1:,:].iloc[xRows].index.to_numpy()\n",
    "    dfCleanEpochIdx = dfCleanRow.set_index('epoch')\n",
    "    profit = dfCleanEpochIdx.loc[xEpochs][target].sum()\n",
    "    profitPerTrade = profit / len(xRows)\n",
    "    return profit, profitPerTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit, profitPerTrade = calculateProfitS(dfCleanRow, dX_test, yTest1D, pred, lookback=max(lstLookback), specificity=.9, target='targetBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2270d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Global profit : ', profit)\n",
    "print('Average profit per trade : ', profitPerTrade)\n",
    "print('Global Number of trade made : ', profit / profitPerTrade)\n",
    "print('Average number of trade made per day : ', (profit / profitPerTrade) / len(pred) * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b16edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit, profitPerTrade = calculateProfitQ(dfCleanRow, dX_test, yTest1D, pred, lookback=max(lstLookback), quantile=.9, target='targetBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f81cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Global profit : ', profit)\n",
    "print('Average profit per trade : ', profitPerTrade)\n",
    "print('Global Number of trade made : ', profit / profitPerTrade)\n",
    "print('Average number of trade made per day : ', (profit / profitPerTrade) / len(pred) * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19312202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
